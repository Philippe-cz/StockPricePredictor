{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.9.1\n",
      "\n",
      "window size:  5\n",
      "formation_window:  4\n",
      "target_window:  1\n",
      "chart period:  w\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import os\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "\n",
    "excel_reports = \".\\Excel reports\"\n",
    "saved_models = \".\\Saved models\"\n",
    "trained_models = \".\\Trained models\"\n",
    "tested_models = \".\\Tested models\"\n",
    "\n",
    "# Initiate parameters\n",
    "ticker = 'mrk'\n",
    "period = \"w\" # EODAPI = \"w\" YahooAPI - \"1wk\"\n",
    "\n",
    "eod_api = True\n",
    "api_key = ''\n",
    "\n",
    "sentiment = True\n",
    "# Sentiment types...\n",
    "# APISentiment\tVaderSentiment\tCombinedVaderSentiment RobertaLargeSentiment #TwitterSentiment\n",
    "sentiment_type = 'CombinedVaderSentiment'\n",
    "aggr_function = 'median'\n",
    "\n",
    "formation_window = 4\n",
    "target_window = 1\n",
    "\n",
    "split_ratio = 0.80\n",
    "\n",
    "# Do not change\n",
    "window_size = formation_window + 1\n",
    "\n",
    "if sentiment == False:\n",
    "    news_df = None\n",
    "if sentiment_type == 'TwitterSentiment':\n",
    "    twitter = True\n",
    "else:\n",
    "    twitter = False\n",
    "    \n",
    "# Print stuffs\n",
    "print(\"\\nwindow size: \", window_size)\n",
    "print(\"formation_window: \", formation_window)\n",
    "print(\"target_window: \", target_window)\n",
    "print(\"chart period: \", period)\n",
    "\n",
    "# training batches\n",
    "batch_size_train = 16\n",
    "batch_size_valid = 4\n",
    "\n",
    "# Period model is trained and tested\n",
    "start_date = '2020-01-01'  # ''2020-01-01   2015-01-01\n",
    "end_date = '2022-10-08'  # '' 2022-08-17\n",
    "\n",
    "# #Delete folders\n",
    "shutil.rmtree(excel_reports)\n",
    "shutil.rmtree(saved_models)\n",
    "shutil.rmtree(trained_models)\n",
    "shutil.rmtree(tested_models)\n",
    "\n",
    "# Create folder, if exist pass exception\n",
    "try:\n",
    "    os.mkdir(\"Excel reports\")\n",
    "    os.mkdir(\"Saved models\")\n",
    "    os.mkdir(\"Trained models\")\n",
    "    os.mkdir(\"Tested models\")\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\z0040jeb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\z0040jeb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------> GetNews completed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>APISentiment</th>\n",
       "      <th>VaderSentiment</th>\n",
       "      <th>CombinedVaderSentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>A Stock's Price \"Tells You Almost Nothing\"</td>\n",
       "      <td>Last time we played The Market Cap Game Show, ...</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>Merck (NYSE:MRK) shareholders have earned a 11...</td>\n",
       "      <td>If you buy and hold a stock for many years, yo...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>Merck's (MRK) Stock Up on Januvia Patent Win A...</td>\n",
       "      <td>Merck’s MRK stock was up 3.5% on Thursday afte...</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>1.5629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>Pharma Stock Roundup: EU Nod to AZN &amp;amp; RHHB...</td>\n",
       "      <td>This week, the European Commission (EC) grante...</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>10 Most Shorted Stocks in September</td>\n",
       "      <td>In this article, we discuss the 10 most shorte...</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>Pioneer VCT Fund Buys Live Nation Entertainmen...</td>\n",
       "      <td>Investment company Pioneer VCT Fund (Current P...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>1.4165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>Variable Portfolio - Partners International Gr...</td>\n",
       "      <td>Investment company Variable Portfolio - Partne...</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>1.3798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>Portfolio manager breaks down market worries o...</td>\n",
       "      <td>John Petrides, portfolio manager at Tocquevill...</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>-0.4985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>BioInvent announces positive early data from o...</td>\n",
       "      <td>LUND, SE / ACCESSWIRE / December 17, 2021 / Bi...</td>\n",
       "      <td>0.972</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.9204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>Omicron: 'There isn't a political appetite' to...</td>\n",
       "      <td>Howard Forman joins Yahoo Finance Live to disc...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                              Title  \\\n",
       "0    2022-09-24         A Stock's Price \"Tells You Almost Nothing\"   \n",
       "1    2022-09-24  Merck (NYSE:MRK) shareholders have earned a 11...   \n",
       "2    2022-09-23  Merck's (MRK) Stock Up on Januvia Patent Win A...   \n",
       "3    2022-09-23  Pharma Stock Roundup: EU Nod to AZN &amp; RHHB...   \n",
       "4    2022-09-23                10 Most Shorted Stocks in September   \n",
       "..          ...                                                ...   \n",
       "985  2021-12-19  Pioneer VCT Fund Buys Live Nation Entertainmen...   \n",
       "986  2021-12-17  Variable Portfolio - Partners International Gr...   \n",
       "987  2021-12-17  Portfolio manager breaks down market worries o...   \n",
       "988  2021-12-17  BioInvent announces positive early data from o...   \n",
       "989  2021-12-17  Omicron: 'There isn't a political appetite' to...   \n",
       "\n",
       "                                               Content  APISentiment  \\\n",
       "0    Last time we played The Market Cap Game Show, ...         0.671   \n",
       "1    If you buy and hold a stock for many years, yo...         0.999   \n",
       "2    Merck’s MRK stock was up 3.5% on Thursday afte...         0.977   \n",
       "3    This week, the European Commission (EC) grante...         0.997   \n",
       "4    In this article, we discuss the 10 most shorte...         0.994   \n",
       "..                                                 ...           ...   \n",
       "985  Investment company Pioneer VCT Fund (Current P...         0.995   \n",
       "986  Investment company Variable Portfolio - Partne...         0.998   \n",
       "987  John Petrides, portfolio manager at Tocquevill...        -0.077   \n",
       "988  LUND, SE / ACCESSWIRE / December 17, 2021 / Bi...         0.972   \n",
       "989  Howard Forman joins Yahoo Finance Live to disc...         0.000   \n",
       "\n",
       "     VaderSentiment  CombinedVaderSentiment  \n",
       "0            0.0000                  0.6710  \n",
       "1            0.0000                  0.9990  \n",
       "2            0.5859                  1.5629  \n",
       "3            0.0000                  0.9970  \n",
       "4            0.0000                  0.9940  \n",
       "..              ...                     ...  \n",
       "985          0.4215                  1.4165  \n",
       "986          0.3818                  1.3798  \n",
       "987         -0.4215                 -0.4985  \n",
       "988         -0.0516                  0.9204  \n",
       "989          0.0000                  0.0000  \n",
       "\n",
       "[990 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if sentiment == True:\n",
    "\n",
    "    from sentiment import GetNews\n",
    "\n",
    "    GetNewsAPI = GetNews()\n",
    "\n",
    "    GetNewsAPI.fit(ticker=ticker, start_date=start_date, end_date=end_date,\n",
    "                   n_news=1000, token=api_key, offset=0, export_excel=True, twitter=twitter)\n",
    "    news_df = GetNewsAPI.transform()\n",
    "news_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   open     high     low  close  adjusted_close    volume\n",
      "0  2020-01-02  91.08  92.1400  90.365  91.25         79.4224  13510415\n",
      "1  2020-01-06  91.23  91.7350  88.410  89.53         77.9254  47256926\n",
      "2  2020-01-13  89.52  92.0554  88.870  90.97         79.1787  43785406\n",
      "3  2020-01-21  90.72  90.9700  85.580  85.98         74.8355  43870859\n",
      "4  2020-01-27  85.10  88.1600  84.710  85.44         74.3655  47226440\n",
      "initial shape:  (145, 6)\n",
      "Output shape:  (705, 10)\n",
      "--------> PullData completed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>EMA6</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA24</th>\n",
       "      <th>CombinedVaderSentiment</th>\n",
       "      <th>trades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02 00:00:00</td>\n",
       "      <td>91.08</td>\n",
       "      <td>92.1400</td>\n",
       "      <td>90.365</td>\n",
       "      <td>91.25</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-06 00:00:00</td>\n",
       "      <td>91.23</td>\n",
       "      <td>91.7350</td>\n",
       "      <td>88.410</td>\n",
       "      <td>89.53</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-13 00:00:00</td>\n",
       "      <td>89.52</td>\n",
       "      <td>92.0554</td>\n",
       "      <td>88.870</td>\n",
       "      <td>90.97</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-21 00:00:00</td>\n",
       "      <td>90.72</td>\n",
       "      <td>90.9700</td>\n",
       "      <td>85.580</td>\n",
       "      <td>85.98</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Month</td>\n",
       "      <td>85.10</td>\n",
       "      <td>88.1600</td>\n",
       "      <td>84.710</td>\n",
       "      <td>85.44</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-06 00:00:00</td>\n",
       "      <td>91.23</td>\n",
       "      <td>91.7350</td>\n",
       "      <td>88.410</td>\n",
       "      <td>89.53</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-13 00:00:00</td>\n",
       "      <td>89.52</td>\n",
       "      <td>92.0554</td>\n",
       "      <td>88.870</td>\n",
       "      <td>90.97</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-21 00:00:00</td>\n",
       "      <td>90.72</td>\n",
       "      <td>90.9700</td>\n",
       "      <td>85.580</td>\n",
       "      <td>85.98</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-27 00:00:00</td>\n",
       "      <td>85.10</td>\n",
       "      <td>88.1600</td>\n",
       "      <td>84.710</td>\n",
       "      <td>85.44</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Month</td>\n",
       "      <td>86.04</td>\n",
       "      <td>89.2000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>85.08</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-13 00:00:00</td>\n",
       "      <td>89.52</td>\n",
       "      <td>92.0554</td>\n",
       "      <td>88.870</td>\n",
       "      <td>90.97</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-21 00:00:00</td>\n",
       "      <td>90.72</td>\n",
       "      <td>90.9700</td>\n",
       "      <td>85.580</td>\n",
       "      <td>85.98</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-27 00:00:00</td>\n",
       "      <td>85.10</td>\n",
       "      <td>88.1600</td>\n",
       "      <td>84.710</td>\n",
       "      <td>85.44</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-02-03 00:00:00</td>\n",
       "      <td>86.04</td>\n",
       "      <td>89.2000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>85.08</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Month</td>\n",
       "      <td>85.08</td>\n",
       "      <td>86.0000</td>\n",
       "      <td>81.450</td>\n",
       "      <td>82.65</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-21 00:00:00</td>\n",
       "      <td>90.72</td>\n",
       "      <td>90.9700</td>\n",
       "      <td>85.580</td>\n",
       "      <td>85.98</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-27 00:00:00</td>\n",
       "      <td>85.10</td>\n",
       "      <td>88.1600</td>\n",
       "      <td>84.710</td>\n",
       "      <td>85.44</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-02-03 00:00:00</td>\n",
       "      <td>86.04</td>\n",
       "      <td>89.2000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>85.08</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-02-10 00:00:00</td>\n",
       "      <td>85.08</td>\n",
       "      <td>86.0000</td>\n",
       "      <td>81.450</td>\n",
       "      <td>82.65</td>\n",
       "      <td>86.501190</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Month</td>\n",
       "      <td>82.88</td>\n",
       "      <td>83.1100</td>\n",
       "      <td>81.570</td>\n",
       "      <td>82.34</td>\n",
       "      <td>88.041667</td>\n",
       "      <td>83.3425</td>\n",
       "      <td>81.040417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date   Open     High     Low  Close       EMA6    EMA12  \\\n",
       "0  2020-01-02 00:00:00  91.08  92.1400  90.365  91.25  88.041667  83.3425   \n",
       "1  2020-01-06 00:00:00  91.23  91.7350  88.410  89.53  88.041667  83.3425   \n",
       "2  2020-01-13 00:00:00  89.52  92.0554  88.870  90.97  88.041667  83.3425   \n",
       "3  2020-01-21 00:00:00  90.72  90.9700  85.580  85.98  88.041667  83.3425   \n",
       "0                Month  85.10  88.1600  84.710  85.44  88.041667  83.3425   \n",
       "1  2020-01-06 00:00:00  91.23  91.7350  88.410  89.53  88.041667  83.3425   \n",
       "2  2020-01-13 00:00:00  89.52  92.0554  88.870  90.97  88.041667  83.3425   \n",
       "3  2020-01-21 00:00:00  90.72  90.9700  85.580  85.98  88.041667  83.3425   \n",
       "4  2020-01-27 00:00:00  85.10  88.1600  84.710  85.44  88.041667  83.3425   \n",
       "0                Month  86.04  89.2000  84.000  85.08  88.041667  83.3425   \n",
       "2  2020-01-13 00:00:00  89.52  92.0554  88.870  90.97  88.041667  83.3425   \n",
       "3  2020-01-21 00:00:00  90.72  90.9700  85.580  85.98  88.041667  83.3425   \n",
       "4  2020-01-27 00:00:00  85.10  88.1600  84.710  85.44  88.041667  83.3425   \n",
       "5  2020-02-03 00:00:00  86.04  89.2000  84.000  85.08  88.041667  83.3425   \n",
       "0                Month  85.08  86.0000  81.450  82.65  88.041667  83.3425   \n",
       "3  2020-01-21 00:00:00  90.72  90.9700  85.580  85.98  88.041667  83.3425   \n",
       "4  2020-01-27 00:00:00  85.10  88.1600  84.710  85.44  88.041667  83.3425   \n",
       "5  2020-02-03 00:00:00  86.04  89.2000  84.000  85.08  88.041667  83.3425   \n",
       "6  2020-02-10 00:00:00  85.08  86.0000  81.450  82.65  86.501190  83.3425   \n",
       "0                Month  82.88  83.1100  81.570  82.34  88.041667  83.3425   \n",
       "\n",
       "       EMA24  CombinedVaderSentiment  trades  \n",
       "0  81.040417                     0.0       1  \n",
       "1  81.040417                     0.0       1  \n",
       "2  81.040417                     0.0       1  \n",
       "3  81.040417                     0.0       1  \n",
       "0  81.040417                     0.0       1  \n",
       "1  81.040417                     0.0       2  \n",
       "2  81.040417                     0.0       2  \n",
       "3  81.040417                     0.0       2  \n",
       "4  81.040417                     0.0       2  \n",
       "0  81.040417                     0.0       2  \n",
       "2  81.040417                     0.0       3  \n",
       "3  81.040417                     0.0       3  \n",
       "4  81.040417                     0.0       3  \n",
       "5  81.040417                     0.0       3  \n",
       "0  81.040417                     0.0       3  \n",
       "3  81.040417                     0.0       4  \n",
       "4  81.040417                     0.0       4  \n",
       "5  81.040417                     0.0       4  \n",
       "6  81.040417                     0.0       4  \n",
       "0  81.040417                     0.0       4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers_preprocess import PullData\n",
    "\n",
    "GetData = PullData()\n",
    "\n",
    "GetData.fit(ticker=ticker,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            interval=period,  # 1wk\n",
    "            progress=False,\n",
    "            condition=False,\n",
    "            form_window=formation_window,\n",
    "            target_window=target_window,\n",
    "            timeperiod1=6,\n",
    "            timeperiod2=12,\n",
    "            timeperiod3=24,\n",
    "            export_excel=True,\n",
    "            excel_path=excel_reports,\n",
    "            listed_conditions=None,\n",
    "            sentiment=sentiment,\n",
    "            sentiment_type=sentiment_type, #sentiment_type\n",
    "            news_df=news_df,\n",
    "            chart_period=period,\n",
    "            sentiment_aggr=aggr_function,\n",
    "            eod_API=eod_api,\n",
    "            eod_key=api_key\n",
    "            )\n",
    "\n",
    "data_prep = GetData.transform()\n",
    "\n",
    "# Validation\n",
    "if window_size != (formation_window + 1):\n",
    "    raise Exception(\n",
    "        f\"Error - window_size ({window_size}) must be equal to sum of formation_window ({formation_window}) and value 1.\")\n",
    "data_prep.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (705, 10)\n",
      "Number of formations:  141\n",
      "--------> NormalizeData completed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>EMA6</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA24</th>\n",
       "      <th>CombinedVaderSentiment</th>\n",
       "      <th>maxv</th>\n",
       "      <th>minv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840084</td>\n",
       "      <td>0.919817</td>\n",
       "      <td>0.630767</td>\n",
       "      <td>0.207403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.14</td>\n",
       "      <td>81.040417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.918015</td>\n",
       "      <td>0.963512</td>\n",
       "      <td>0.663951</td>\n",
       "      <td>0.764856</td>\n",
       "      <td>0.630767</td>\n",
       "      <td>0.207403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.14</td>\n",
       "      <td>81.040417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.763955</td>\n",
       "      <td>0.992378</td>\n",
       "      <td>0.705394</td>\n",
       "      <td>0.894591</td>\n",
       "      <td>0.630767</td>\n",
       "      <td>0.207403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.14</td>\n",
       "      <td>81.040417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.872067</td>\n",
       "      <td>0.894591</td>\n",
       "      <td>0.408987</td>\n",
       "      <td>0.445024</td>\n",
       "      <td>0.630767</td>\n",
       "      <td>0.207403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.14</td>\n",
       "      <td>81.040417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.365742</td>\n",
       "      <td>0.641428</td>\n",
       "      <td>0.330606</td>\n",
       "      <td>0.396374</td>\n",
       "      <td>0.630767</td>\n",
       "      <td>0.207403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.14</td>\n",
       "      <td>81.040417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close      EMA6     EMA12  EMA24  \\\n",
       "0  0.904501  1.000000  0.840084  0.919817  0.630767  0.207403    0.0   \n",
       "1  0.918015  0.963512  0.663951  0.764856  0.630767  0.207403    0.0   \n",
       "2  0.763955  0.992378  0.705394  0.894591  0.630767  0.207403    0.0   \n",
       "3  0.872067  0.894591  0.408987  0.445024  0.630767  0.207403    0.0   \n",
       "0  0.365742  0.641428  0.330606  0.396374  0.630767  0.207403    0.0   \n",
       "\n",
       "   CombinedVaderSentiment   maxv       minv  \n",
       "0                     0.0  92.14  81.040417  \n",
       "1                     0.0  92.14  81.040417  \n",
       "2                     0.0  92.14  81.040417  \n",
       "3                     0.0  92.14  81.040417  \n",
       "0                     0.0  92.14  81.040417  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "from transformers_preprocess import NormalizeData\n",
    "\n",
    "NormalizeData = NormalizeData()\n",
    "\n",
    "NormalizeData.fit(window_size=window_size, shuffle=False, debug=False,\n",
    "                  export_excel=True, excel_path=excel_reports, sentiment=sentiment)\n",
    "\n",
    "data_normalized, Dates = NormalizeData.transform(data_prep)\n",
    "data_normalized.head()\n",
    "# Get only forecasts for model testing\n",
    "# x_valid_x = data_normalized[['maxv','minv']].copy() #extreme values for reverting normalization\n",
    "# x_valid = data_normalized.iloc[:,:-2].copy() #dataset for forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split ratio: 80 %\n",
      "train period: 2020-01-02 - 2022-03-14\n",
      "valid period: 2022-02-28 - 2022-09-26\n",
      "x_train window:  113.0\n",
      "x_valid window:  28.0\n",
      "--------> SplitData completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "from training import SplitData\n",
    "\n",
    "SplitData = SplitData()\n",
    "\n",
    "SplitData.fit(split_ratio=split_ratio, window_size=window_size,\n",
    "              dates=Dates, debug=False, export_excel=True, excel_path=excel_reports, sentiment=sentiment)\n",
    "\n",
    "x_train, x_valid, x_train_x, x_valid_x = SplitData.transform(data_normalized)\n",
    "# x_train.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------> GetTensoredDataset completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from training import GetTensoredDataset\n",
    "\n",
    "GetTensoredDataset = GetTensoredDataset()\n",
    "\n",
    "GetTensoredDataset.fit(window_size=window_size, batch_size=batch_size_train, train=True, debug=False)\n",
    "\n",
    "x_train_tensors, _ = GetTensoredDataset.transform(x_train)\n",
    "\n",
    "# c = 0\n",
    "# for batch in x_train_tensors:\n",
    "#     if c < 3:\n",
    "#         print(batch)\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------> GetTensoredDataset completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from training import GetTensoredDataset\n",
    "\n",
    "GetTensoredValidDataset = GetTensoredDataset()\n",
    "\n",
    "GetTensoredValidDataset.fit(\n",
    "    window_size=window_size, batch_size=batch_size_valid, train=False, debug=False)\n",
    "\n",
    "x_valid_tensors, labels = GetTensoredValidDataset.transform(x_valid)\n",
    "\n",
    "# for batch in x_valid_tensors:\n",
    "#     if c < 3:\n",
    "#         print(batch)\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Training</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model_name = f'{saved_models}/{str.upper(ticker)}_{formation_window}_{target_window}_{window_size}_{split_ratio}_{period}_{sentiment}_{start_date}_{end_date}.h5'\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=6, mode='min', restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=10e-15,\n",
    "                              verbose=0)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss',\n",
    "                                   filepath=model_name,\n",
    "                                   save_best_only=True)\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr, model_checkpoint]\n",
    "\n",
    "\n",
    "def sign_penalty(y_true, y_pred):\n",
    "    penalty = 100.\n",
    "    loss = tf.where(tf.less(y_true*y_pred, 0),\n",
    "                    penalty * tf.square(y_true-y_pred),\n",
    "                    tf.square(y_true - y_pred)\n",
    "                    )\n",
    "\n",
    "    return(tf.reduce_mean(loss, axis=-1))\n",
    "\n",
    "\n",
    "tf.keras.losses.sign_penalty = sign_penalty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow code is used to find the best model architecture, recommended to use cloud computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started at  12:27:53\n",
      "------ > Layer:  4\n",
      "CNN-nodes-2_kernel1lstmBI-2_lstm-2_dense2\n",
      "CNN-nodes-2_kernel10lstmBI-2_lstm-2_dense2\n",
      "CNN-nodes-2_kernel1lstmBI-2_lstm-2_dense3\n",
      "CNN-nodes-2_kernel10lstmBI-2_lstm-2_dense3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2648\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2647\u001b[0m \u001b[39mwith\u001b[39;00m c_api_util\u001b[39m.\u001b[39mtf_buffer() \u001b[39mas\u001b[39;00m buf:\n\u001b[1;32m-> 2648\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39;49mTF_OperationGetAttrValueProto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_op, name, buf)\n\u001b[0;32m   2649\u001b[0m   data \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_GetBuffer(buf)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Operation 'strided_slice' has no attr named '_read_only_resource_inputs'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps_utils.py:105\u001b[0m, in \u001b[0;36mget_read_write_resource_inputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m   read_only_input_indices \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49mget_attr(READ_ONLY_RESOURCE_INPUTS_ATTR)\n\u001b[0;32m    106\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m   \u001b[39m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2652\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2650\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   2651\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 2652\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n\u001b[0;32m   2653\u001b[0m x \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "\u001b[1;31mValueError\u001b[0m: Operation 'strided_slice' has no attr named '_read_only_resource_inputs'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\01_main.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m------ > Layer: \u001b[39m\u001b[39m\"\u001b[39m,layer)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     all_models, names \u001b[39m=\u001b[39m get_models(num_layers\u001b[39m=\u001b[39;49mlayer, \u001b[39mmin\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39mmax\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, node_step_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, features\u001b[39m=\u001b[39;49mx_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     optimizing_df \u001b[39m=\u001b[39m optimize(models\u001b[39m=\u001b[39mall_models,X_train\u001b[39m=\u001b[39mx_train_tensors,X_valid\u001b[39m=\u001b[39mx_valid_tensors,X_test\u001b[39m=\u001b[39mx_valid,labels\u001b[39m=\u001b[39mlabels,epochs\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,window_size\u001b[39m=\u001b[39mwindow_size,callbacks\u001b[39m=\u001b[39mcallbacks,layer\u001b[39m=\u001b[39mlayer,ticker\u001b[39m=\u001b[39mticker,excel_path\u001b[39m=\u001b[39mtested_models)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# optimizing_df\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m#f_df = f_df.append(optimizing_df)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\testing.py:48\u001b[0m, in \u001b[0;36mget_models\u001b[1;34m(num_layers, min, max, node_step_size, features, hidden_layer_activation, num_nodes_at_output, output_layer_activation)\u001b[0m\n\u001b[0;32m     45\u001b[0m     model_name \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCNN-nodes-\u001b[39m\u001b[39m{\u001b[39;00mnodes_at_layer\u001b[39m}\u001b[39;00m\u001b[39m_kernel\u001b[39m\u001b[39m{\u001b[39;00mkernel\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m     47\u001b[0m \u001b[39mif\u001b[39;00m counter_lstm \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m counter_cnn \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 48\u001b[0m     model\u001b[39m.\u001b[39;49madd(tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mBidirectional(\n\u001b[0;32m     49\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mLSTM(nodes_at_layer, return_sequences\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)))\n\u001b[0;32m     50\u001b[0m     model_name \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlstmBI-\u001b[39m\u001b[39m{\u001b[39;00mnodes_at_layer\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[39mif\u001b[39;00m counter_lstm \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\engine\\sequential.py:220\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_explicit_input_shape \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs:\n\u001b[0;32m    218\u001b[0m   \u001b[39m# If the model is being built continuously on top of an input layer:\u001b[39;00m\n\u001b[0;32m    219\u001b[0m   \u001b[39m# refresh its output.\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m   output_tensor \u001b[39m=\u001b[39m layer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutputs[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m    221\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(output_tensor)) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    222\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(SINGLE_LAYER_OUTPUT_ERROR_MSG)\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\layers\\rnn\\bidirectional.py:249\u001b[0m, in \u001b[0;36mBidirectional.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m   inputs \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    248\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 249\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Bidirectional, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    251\u001b[0m \u001b[39m# Applies the same workaround as in `RNN.__call__`\u001b[39;00m\n\u001b[0;32m    252\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\engine\\base_layer.py:944\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    940\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 944\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m    945\u001b[0m                                             input_list)\n\u001b[0;32m    947\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m    948\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\engine\\base_layer.py:2315\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   2310\u001b[0m     training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2312\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[0;32m   2313\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[0;32m   2314\u001b[0m   \u001b[39m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[1;32m-> 2315\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[0;32m   2316\u001b[0m       inputs, input_masks, args, kwargs)\n\u001b[0;32m   2318\u001b[0m   \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2320\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2321\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\engine\\base_layer.py:2186\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m   2184\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature)\n\u001b[0;32m   2185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2186\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\engine\\base_layer.py:2232\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m   2230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m   2231\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m-> 2232\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2234\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[0;32m   2235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[0;32m   2236\u001b[0m                         build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\layers\\rnn\\bidirectional.py:364\u001b[0m, in \u001b[0;36mBidirectional.call\u001b[1;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[0;32m    361\u001b[0m     forward_inputs, backward_inputs \u001b[39m=\u001b[39m inputs, inputs\n\u001b[0;32m    362\u001b[0m     forward_state, backward_state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m   y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_layer(forward_inputs,\n\u001b[0;32m    365\u001b[0m                          initial_state\u001b[39m=\u001b[39;49mforward_state, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    366\u001b[0m   y_rev \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_layer(backward_inputs,\n\u001b[0;32m    367\u001b[0m                               initial_state\u001b[39m=\u001b[39mbackward_state, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py:515\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mstandardize_args(\n\u001b[0;32m    512\u001b[0m     inputs, initial_state, constants, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants)\n\u001b[0;32m    514\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(RNN, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    517\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[0;32m    521\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py:673\u001b[0m, in \u001b[0;36mLSTM.call\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    669\u001b[0m         last_output, outputs, new_h, new_c, runtime \u001b[39m=\u001b[39m standard_lstm(\n\u001b[0;32m    670\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnormal_lstm_kwargs)\n\u001b[0;32m    671\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    672\u001b[0m       (last_output, outputs, new_h, new_c,\n\u001b[1;32m--> 673\u001b[0m        runtime) \u001b[39m=\u001b[39m lstm_with_backend_selection(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnormal_lstm_kwargs)\n\u001b[0;32m    675\u001b[0m   states \u001b[39m=\u001b[39m [new_h, new_c]\n\u001b[0;32m    677\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful:\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py:1183\u001b[0m, in \u001b[0;36mlstm_with_backend_selection\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[0;32m   1177\u001b[0m   defun_gpu_lstm \u001b[39m=\u001b[39m gru_lstm_utils\u001b[39m.\u001b[39mgenerate_defun_backend(\n\u001b[0;32m   1178\u001b[0m       api_name, gru_lstm_utils\u001b[39m.\u001b[39mGPU_DEVICE_NAME, gpu_lstm_with_fallback,\n\u001b[0;32m   1179\u001b[0m       supportive_attribute)\n\u001b[0;32m   1181\u001b[0m   \u001b[39m# Call the normal LSTM impl and register the cuDNN impl function. The\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m   \u001b[39m# grappler will kick in during session execution to optimize the graph.\u001b[39;00m\n\u001b[1;32m-> 1183\u001b[0m   last_output, outputs, new_h, new_c, runtime \u001b[39m=\u001b[39m defun_standard_lstm(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[0;32m   1184\u001b[0m   gru_lstm_utils\u001b[39m.\u001b[39mfunction_register(defun_gpu_lstm, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m   1186\u001b[0m \u001b[39mreturn\u001b[39;00m last_output, outputs, new_h, new_c, runtime\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2452\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2449\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m-> 2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mgraph_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m   cache_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mgeneralize(cache_key)\n\u001b[0;32m   2709\u001b[0m   (args, kwargs) \u001b[39m=\u001b[39m cache_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2711\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                          graph_function)\n\u001b[0;32m   2715\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2622\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2624\u001b[0m ]\n\u001b[0;32m   2625\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2626\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2629\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2630\u001b[0m         args,\n\u001b[0;32m   2631\u001b[0m         kwargs,\n\u001b[0;32m   2632\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2633\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2634\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2635\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2636\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2638\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2639\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2641\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2644\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1182\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1176\u001b[0m   \u001b[39m# Returning a closed-over tensor does not trigger convert_to_tensor.\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m   func_graph\u001b[39m.\u001b[39moutputs\u001b[39m.\u001b[39mextend(\n\u001b[0;32m   1178\u001b[0m       func_graph\u001b[39m.\u001b[39mcapture(x)\n\u001b[0;32m   1179\u001b[0m       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m flatten(func_graph\u001b[39m.\u001b[39mstructured_outputs)\n\u001b[0;32m   1180\u001b[0m       \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1182\u001b[0m   func_graph\u001b[39m.\u001b[39mvariables \u001b[39m=\u001b[39m variables\n\u001b[0;32m   1184\u001b[0m \u001b[39mif\u001b[39;00m add_control_dependencies:\n\u001b[0;32m   1185\u001b[0m   func_graph\u001b[39m.\u001b[39mcontrol_outputs\u001b[39m.\u001b[39mextend(deps_control_manager\u001b[39m.\u001b[39mops_which_must_run)\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py:464\u001b[0m, in \u001b[0;36mAutomaticControlDependencies.__exit__\u001b[1;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[0;32m    461\u001b[0m resource_inputs \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    462\u001b[0m \u001b[39m# Check for any resource inputs. If we find any, we update control_inputs\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[39m# and last_write_to_resource.\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m \u001b[39mfor\u001b[39;00m inp, resource_type \u001b[39min\u001b[39;00m _get_resource_inputs(op):\n\u001b[0;32m    465\u001b[0m   is_read \u001b[39m=\u001b[39m resource_type \u001b[39m==\u001b[39m ResourceType\u001b[39m.\u001b[39mREAD_ONLY\n\u001b[0;32m    466\u001b[0m   input_id \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mtensor_id(inp)\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py:662\u001b[0m, in \u001b[0;36m_get_resource_inputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_resource_inputs\u001b[39m(op):\n\u001b[0;32m    661\u001b[0m   \u001b[39m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 662\u001b[0m   reads, writes \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mget_read_write_resource_inputs(op)\n\u001b[0;32m    663\u001b[0m   saturated \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    664\u001b[0m   \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m saturated:\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps_utils.py:108\u001b[0m, in \u001b[0;36mget_read_write_resource_inputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    105\u001b[0m   read_only_input_indices \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39mget_attr(READ_ONLY_RESOURCE_INPUTS_ATTR)\n\u001b[0;32m    106\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m   \u001b[39m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m   writes\u001b[39m.\u001b[39mupdate(t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m op\u001b[39m.\u001b[39;49minputs \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mresource)\n\u001b[0;32m    109\u001b[0m   \u001b[39mreturn\u001b[39;00m (reads, writes)\n\u001b[0;32m    111\u001b[0m read_only_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2479\u001b[0m, in \u001b[0;36mOperation.inputs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2476\u001b[0m \u001b[39m\"\"\"The sequence of `Tensor` objects representing the data inputs of this op.\"\"\"\u001b[39;00m\n\u001b[0;32m   2477\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inputs_val \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2478\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2479\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inputs_val \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(\n\u001b[0;32m   2480\u001b[0m       \u001b[39mmap\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph\u001b[39m.\u001b[39;49m_get_tensor_by_tf_output,\n\u001b[0;32m   2481\u001b[0m           pywrap_tf_session\u001b[39m.\u001b[39;49mGetOperationInputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_op)))\n\u001b[0;32m   2482\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m   2483\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inputs_val\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4143\u001b[0m, in \u001b[0;36mGraph._get_tensor_by_tf_output\u001b[1;34m(self, tf_output)\u001b[0m\n\u001b[0;32m   4130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_tensor_by_tf_output\u001b[39m(\u001b[39mself\u001b[39m, tf_output):\n\u001b[0;32m   4131\u001b[0m   \u001b[39m\"\"\"Returns the `Tensor` representing `tf_output`.\u001b[39;00m\n\u001b[0;32m   4132\u001b[0m \n\u001b[0;32m   4133\u001b[0m \u001b[39m  Note that there is only one such `Tensor`, i.e. multiple calls to this\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4141\u001b[0m \u001b[39m    The `Tensor` that represents `tf_output`.\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4143\u001b[0m   op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_operation_by_tf_operation(tf_output\u001b[39m.\u001b[39;49moper)\n\u001b[0;32m   4144\u001b[0m   \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39moutputs[tf_output\u001b[39m.\u001b[39mindex]\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\04_stockprediction\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4106\u001b[0m, in \u001b[0;36mGraph._get_operation_by_tf_operation\u001b[1;34m(self, tf_oper)\u001b[0m\n\u001b[0;32m   4105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_operation_by_tf_operation\u001b[39m(\u001b[39mself\u001b[39m, tf_oper):\n\u001b[1;32m-> 4106\u001b[0m   op_name \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_OperationName(tf_oper)\n\u001b[0;32m   4107\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_operation_by_name_unsafe(op_name)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "start = datetime.now()\n",
    "print(\"Training started at \",start_time)\n",
    "tf.random.set_seed(7788)\n",
    "np.random.seed(7788)\n",
    "\n",
    "# #Permutation testing\n",
    "# num_layers = 2\n",
    "# min, max = 2, 4\n",
    "# node_step_size = 2\n",
    "# node_options = list(range(min, max + 1, node_step_size))\n",
    "# two_layer_possibilities = [node_options, node_options]\n",
    "# layer_node_permutations  = list(itertools.product(*two_layer_possibilities))\n",
    "\n",
    "from testing import *\n",
    "f_df = pd.DataFrame()\n",
    "\n",
    "for layer in range(4,5):\n",
    "    print(\"------ > Layer: \",layer)\n",
    "    all_models, names = get_models(num_layers=layer, min=2, max=3, node_step_size=1, features=x_train.shape[1])\n",
    "    optimizing_df = optimize(models=all_models,X_train=x_train_tensors,X_valid=x_valid_tensors,X_test=x_valid,labels=labels,epochs=1000,verbose=0,window_size=window_size,callbacks=callbacks,layer=layer,ticker=ticker,excel_path=tested_models)\n",
    "# optimizing_df\n",
    "    #f_df = f_df.append(optimizing_df)\n",
    "    \n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "end = datetime.now()\n",
    "print(\"\\nTraining ended at \",end_time) \n",
    "print(f\"Training ended in {round((end-start).total_seconds(),2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(optimizing_df))\n",
    "# optimizing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started at  12:52:31\n",
      "Model training - MRK \n",
      "\n",
      "Epoch 1/1000\n",
      "8/8 [==============================] - 9s 436ms/step - loss: 0.4887 - val_loss: 0.5196 - lr: 7.0000e-04\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3839 - val_loss: 0.4311 - lr: 7.0000e-04\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2966 - val_loss: 0.3567 - lr: 7.0000e-04\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2305 - val_loss: 0.2935 - lr: 7.0000e-04\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1801 - val_loss: 0.2395 - lr: 7.0000e-04\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1416 - val_loss: 0.1942 - lr: 7.0000e-04\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1129 - val_loss: 0.1576 - lr: 7.0000e-04\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0927 - val_loss: 0.1294 - lr: 7.0000e-04\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0792 - val_loss: 0.1086 - lr: 7.0000e-04\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0709 - val_loss: 0.0937 - lr: 7.0000e-04\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0662 - val_loss: 0.0835 - lr: 7.0000e-04\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0639 - val_loss: 0.0766 - lr: 7.0000e-04\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0629 - val_loss: 0.0720 - lr: 7.0000e-04\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0626 - val_loss: 0.0690 - lr: 7.0000e-04\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0625 - val_loss: 0.0670 - lr: 7.0000e-04\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0626 - val_loss: 0.0657 - lr: 7.0000e-04\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0625 - val_loss: 0.0648 - lr: 7.0000e-04\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0624 - val_loss: 0.0641 - lr: 7.0000e-04\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0623 - val_loss: 0.0637 - lr: 7.0000e-04\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0620 - val_loss: 0.0633 - lr: 7.0000e-04\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0618 - val_loss: 0.0630 - lr: 7.0000e-04\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0615 - val_loss: 0.0628 - lr: 7.0000e-04\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0612 - val_loss: 0.0626 - lr: 7.0000e-04\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0609 - val_loss: 0.0624 - lr: 7.0000e-04\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0606 - val_loss: 0.0621 - lr: 7.0000e-04\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0603 - val_loss: 0.0619 - lr: 7.0000e-04\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0599 - val_loss: 0.0617 - lr: 7.0000e-04\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0596 - val_loss: 0.0615 - lr: 7.0000e-04\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0593 - val_loss: 0.0612 - lr: 7.0000e-04\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0589 - val_loss: 0.0610 - lr: 7.0000e-04\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0586 - val_loss: 0.0608 - lr: 7.0000e-04\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0582 - val_loss: 0.0605 - lr: 7.0000e-04\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0579 - val_loss: 0.0603 - lr: 7.0000e-04\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0575 - val_loss: 0.0600 - lr: 7.0000e-04\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0571 - val_loss: 0.0598 - lr: 7.0000e-04\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0567 - val_loss: 0.0595 - lr: 7.0000e-04\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0563 - val_loss: 0.0593 - lr: 7.0000e-04\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0559 - val_loss: 0.0590 - lr: 7.0000e-04\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0555 - val_loss: 0.0587 - lr: 7.0000e-04\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0551 - val_loss: 0.0584 - lr: 7.0000e-04\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0546 - val_loss: 0.0581 - lr: 7.0000e-04\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0542 - val_loss: 0.0578 - lr: 7.0000e-04\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0537 - val_loss: 0.0575 - lr: 7.0000e-04\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0532 - val_loss: 0.0571 - lr: 7.0000e-04\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0527 - val_loss: 0.0568 - lr: 7.0000e-04\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0522 - val_loss: 0.0564 - lr: 7.0000e-04\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0517 - val_loss: 0.0560 - lr: 7.0000e-04\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0511 - val_loss: 0.0555 - lr: 7.0000e-04\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0506 - val_loss: 0.0551 - lr: 7.0000e-04\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0500 - val_loss: 0.0546 - lr: 7.0000e-04\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0494 - val_loss: 0.0541 - lr: 7.0000e-04\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0488 - val_loss: 0.0536 - lr: 7.0000e-04\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0481 - val_loss: 0.0530 - lr: 7.0000e-04\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0475 - val_loss: 0.0524 - lr: 7.0000e-04\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0468 - val_loss: 0.0517 - lr: 7.0000e-04\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0461 - val_loss: 0.0510 - lr: 7.0000e-04\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0453 - val_loss: 0.0503 - lr: 7.0000e-04\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0445 - val_loss: 0.0494 - lr: 7.0000e-04\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0437 - val_loss: 0.0485 - lr: 7.0000e-04\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0428 - val_loss: 0.0476 - lr: 7.0000e-04\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0419 - val_loss: 0.0466 - lr: 7.0000e-04\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0410 - val_loss: 0.0455 - lr: 7.0000e-04\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0400 - val_loss: 0.0444 - lr: 7.0000e-04\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0390 - val_loss: 0.0432 - lr: 7.0000e-04\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0380 - val_loss: 0.0421 - lr: 7.0000e-04\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0370 - val_loss: 0.0410 - lr: 7.0000e-04\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0360 - val_loss: 0.0399 - lr: 7.0000e-04\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0350 - val_loss: 0.0389 - lr: 7.0000e-04\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0341 - val_loss: 0.0381 - lr: 7.0000e-04\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0333 - val_loss: 0.0374 - lr: 7.0000e-04\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0326 - val_loss: 0.0367 - lr: 7.0000e-04\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0320 - val_loss: 0.0362 - lr: 7.0000e-04\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0315 - val_loss: 0.0357 - lr: 7.0000e-04\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0311 - val_loss: 0.0352 - lr: 7.0000e-04\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0307 - val_loss: 0.0347 - lr: 7.0000e-04\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0303 - val_loss: 0.0342 - lr: 7.0000e-04\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0300 - val_loss: 0.0338 - lr: 7.0000e-04\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0297 - val_loss: 0.0334 - lr: 7.0000e-04\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0295 - val_loss: 0.0331 - lr: 7.0000e-04\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0292 - val_loss: 0.0328 - lr: 7.0000e-04\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0289 - val_loss: 0.0325 - lr: 7.0000e-04\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0287 - val_loss: 0.0324 - lr: 7.0000e-04\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0284 - val_loss: 0.0322 - lr: 7.0000e-04\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0282 - val_loss: 0.0322 - lr: 7.0000e-04\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0279 - val_loss: 0.0322 - lr: 7.0000e-04\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0277 - val_loss: 0.0322 - lr: 1.4000e-04\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0276 - val_loss: 0.0321 - lr: 1.4000e-04\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0276 - val_loss: 0.0321 - lr: 1.4000e-04\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0275 - val_loss: 0.0321 - lr: 1.4000e-04\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0275 - val_loss: 0.0321 - lr: 2.8000e-05\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0275 - val_loss: 0.0321 - lr: 2.8000e-05\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0275 - val_loss: 0.0321 - lr: 5.6000e-06\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0275 - val_loss: 0.0321 - lr: 5.6000e-06\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0274 - val_loss: 0.0321 - lr: 1.1200e-06\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0274 - val_loss: 0.0321 - lr: 1.1200e-06\n",
      "\n",
      "Training ended at  12:52:58\n",
      "Training ended in 27.03 seconds\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "start = datetime.now()\n",
    "print(\"Training started at \",start_time)\n",
    "tf.random.set_seed(7788)\n",
    "np.random.seed(7788)\n",
    "features = x_train.shape[1]\n",
    "\n",
    "print(f\"Model training - {str.upper(ticker)} \\n\")\n",
    "\n",
    "#model = clb_model(features)\n",
    "#model = mrk_model(features)\n",
    "#model =  mrk_model_sent_medium(features)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "        tf.keras.layers.Conv1D(filters=20, kernel_size=1,\n",
    "                               strides=1, padding=\"same\",\n",
    "                               activation=tf.nn.selu,\n",
    "                               input_shape=[None, features]),\n",
    "        tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(3, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(2)),\n",
    "        tf.keras.layers.Dense(2, activation=tf.nn.selu),\n",
    "        tf.keras.layers.Dense(1, activation=tf.nn.relu),\n",
    "    ])\n",
    "\n",
    "\n",
    "optimizer2 = tf.keras.optimizers.Adam(\n",
    "            learning_rate=0.0007, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "optimizer5 = tf.keras.optimizers.Adagrad(\n",
    "    learning_rate=0.005, initial_accumulator_value=5, epsilon=1e-07, name='Adagrad')\n",
    "\n",
    "model.compile(loss=sign_penalty,\n",
    "              optimizer=optimizer2,\n",
    "              )\n",
    "\n",
    "model.fit(x_train_tensors, epochs=1000, callbacks=[\n",
    "          callbacks], validation_data=x_valid_tensors,verbose=1)\n",
    "\n",
    "\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "end = datetime.now()\n",
    "print(\"\\nTraining ended at \",end_time) \n",
    "print(f\"Training ended in {round((end-start).total_seconds(),2)} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "def model_forecast(model, series, window_size, debug):\n",
    "    \"\"\"\n",
    "    Get model, data and window size as an input. \n",
    "    Make prediction window is subtracted by 1, since we do not need label in window, \n",
    "    label value is skipped\n",
    "    \"\"\"\n",
    "    c = 0\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size-1, shift=window_size, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "\n",
    "    if debug == True:\n",
    "        # This block of code will print out data on which is made prediction\n",
    "        for item in ds:\n",
    "            c += 1\n",
    "            if c < 3:\n",
    "                print(\"\\n\"+str(c) + \" prediction:\\n \", item)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    ds = ds.batch(1).prefetch(1)\n",
    "    forecast = model.predict(ds)\n",
    "    forecast2 = np.squeeze(forecast)\n",
    "    return forecast2\n",
    "\n",
    "\n",
    "forecast = model_forecast(model, x_valid, window_size=window_size, debug=False)\n",
    "# result_list = sign_penalty(labels, forecast).numpy()\n",
    "# result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr = x_valid.iloc[:24, :].to_numpy()\n",
    "# pr = np.array([pr])\n",
    "# pr = np.array([pr])\n",
    "# pred = tf.data.Dataset.from_tensor_slices(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------> ReverseNormalization completed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>EMA6</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA24</th>\n",
       "      <th>labels</th>\n",
       "      <th>prediction</th>\n",
       "      <th>CombinedVaderSentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.83</td>\n",
       "      <td>77.8600</td>\n",
       "      <td>74.780</td>\n",
       "      <td>77.83</td>\n",
       "      <td>77.569071</td>\n",
       "      <td>77.924519</td>\n",
       "      <td>78.076373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.01</td>\n",
       "      <td>79.6250</td>\n",
       "      <td>76.080</td>\n",
       "      <td>78.26</td>\n",
       "      <td>77.766479</td>\n",
       "      <td>77.976132</td>\n",
       "      <td>78.091063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.23185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.90</td>\n",
       "      <td>79.7350</td>\n",
       "      <td>77.310</td>\n",
       "      <td>79.11</td>\n",
       "      <td>78.150342</td>\n",
       "      <td>78.150573</td>\n",
       "      <td>78.172578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.67</td>\n",
       "      <td>81.3800</td>\n",
       "      <td>78.765</td>\n",
       "      <td>81.34</td>\n",
       "      <td>79.061673</td>\n",
       "      <td>78.641254</td>\n",
       "      <td>78.425972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.18315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.37</td>\n",
       "      <td>83.5800</td>\n",
       "      <td>80.730</td>\n",
       "      <td>83.52</td>\n",
       "      <td>77.766479</td>\n",
       "      <td>77.976132</td>\n",
       "      <td>78.091063</td>\n",
       "      <td>83.5800</td>\n",
       "      <td>83.286131</td>\n",
       "      <td>1.23185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77.01</td>\n",
       "      <td>79.6250</td>\n",
       "      <td>76.080</td>\n",
       "      <td>78.26</td>\n",
       "      <td>77.766479</td>\n",
       "      <td>77.976132</td>\n",
       "      <td>78.091063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.23185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77.90</td>\n",
       "      <td>79.7350</td>\n",
       "      <td>77.310</td>\n",
       "      <td>79.11</td>\n",
       "      <td>78.150342</td>\n",
       "      <td>78.150573</td>\n",
       "      <td>78.172578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>79.67</td>\n",
       "      <td>81.3800</td>\n",
       "      <td>78.765</td>\n",
       "      <td>81.34</td>\n",
       "      <td>79.061673</td>\n",
       "      <td>78.641254</td>\n",
       "      <td>78.425972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.18315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81.37</td>\n",
       "      <td>83.5800</td>\n",
       "      <td>80.730</td>\n",
       "      <td>83.52</td>\n",
       "      <td>80.335481</td>\n",
       "      <td>79.391830</td>\n",
       "      <td>78.833494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>83.50</td>\n",
       "      <td>87.8350</td>\n",
       "      <td>82.730</td>\n",
       "      <td>87.68</td>\n",
       "      <td>78.150342</td>\n",
       "      <td>78.150573</td>\n",
       "      <td>78.172578</td>\n",
       "      <td>87.8350</td>\n",
       "      <td>86.953958</td>\n",
       "      <td>0.32155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>77.90</td>\n",
       "      <td>79.7350</td>\n",
       "      <td>77.310</td>\n",
       "      <td>79.11</td>\n",
       "      <td>78.150342</td>\n",
       "      <td>78.150573</td>\n",
       "      <td>78.172578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>79.67</td>\n",
       "      <td>81.3800</td>\n",
       "      <td>78.765</td>\n",
       "      <td>81.34</td>\n",
       "      <td>79.061673</td>\n",
       "      <td>78.641254</td>\n",
       "      <td>78.425972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.18315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>81.37</td>\n",
       "      <td>83.5800</td>\n",
       "      <td>80.730</td>\n",
       "      <td>83.52</td>\n",
       "      <td>80.335481</td>\n",
       "      <td>79.391830</td>\n",
       "      <td>78.833494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>83.50</td>\n",
       "      <td>87.8350</td>\n",
       "      <td>82.730</td>\n",
       "      <td>87.68</td>\n",
       "      <td>82.433915</td>\n",
       "      <td>80.666933</td>\n",
       "      <td>79.541215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>88.32</td>\n",
       "      <td>89.4800</td>\n",
       "      <td>84.830</td>\n",
       "      <td>86.91</td>\n",
       "      <td>79.061673</td>\n",
       "      <td>78.641254</td>\n",
       "      <td>78.425972</td>\n",
       "      <td>89.4800</td>\n",
       "      <td>88.904832</td>\n",
       "      <td>0.18315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79.67</td>\n",
       "      <td>81.3800</td>\n",
       "      <td>78.765</td>\n",
       "      <td>81.34</td>\n",
       "      <td>79.061673</td>\n",
       "      <td>78.641254</td>\n",
       "      <td>78.425972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.18315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>81.37</td>\n",
       "      <td>83.5800</td>\n",
       "      <td>80.730</td>\n",
       "      <td>83.52</td>\n",
       "      <td>80.335481</td>\n",
       "      <td>79.391830</td>\n",
       "      <td>78.833494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>83.50</td>\n",
       "      <td>87.8350</td>\n",
       "      <td>82.730</td>\n",
       "      <td>87.68</td>\n",
       "      <td>82.433915</td>\n",
       "      <td>80.666933</td>\n",
       "      <td>79.541215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>88.32</td>\n",
       "      <td>89.4800</td>\n",
       "      <td>84.830</td>\n",
       "      <td>86.91</td>\n",
       "      <td>83.712796</td>\n",
       "      <td>81.627405</td>\n",
       "      <td>80.130718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86.42</td>\n",
       "      <td>87.4502</td>\n",
       "      <td>84.500</td>\n",
       "      <td>84.59</td>\n",
       "      <td>80.335481</td>\n",
       "      <td>79.391830</td>\n",
       "      <td>78.833494</td>\n",
       "      <td>87.4502</td>\n",
       "      <td>88.068110</td>\n",
       "      <td>0.99200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>81.37</td>\n",
       "      <td>83.5800</td>\n",
       "      <td>80.730</td>\n",
       "      <td>83.52</td>\n",
       "      <td>80.335481</td>\n",
       "      <td>79.391830</td>\n",
       "      <td>78.833494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83.50</td>\n",
       "      <td>87.8350</td>\n",
       "      <td>82.730</td>\n",
       "      <td>87.68</td>\n",
       "      <td>82.433915</td>\n",
       "      <td>80.666933</td>\n",
       "      <td>79.541215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>88.32</td>\n",
       "      <td>89.4800</td>\n",
       "      <td>84.830</td>\n",
       "      <td>86.91</td>\n",
       "      <td>83.712796</td>\n",
       "      <td>81.627405</td>\n",
       "      <td>80.130718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>86.42</td>\n",
       "      <td>87.4502</td>\n",
       "      <td>84.500</td>\n",
       "      <td>84.59</td>\n",
       "      <td>83.963426</td>\n",
       "      <td>82.083189</td>\n",
       "      <td>80.487460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.39380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>84.59</td>\n",
       "      <td>90.0100</td>\n",
       "      <td>83.530</td>\n",
       "      <td>88.69</td>\n",
       "      <td>82.433915</td>\n",
       "      <td>80.666933</td>\n",
       "      <td>79.541215</td>\n",
       "      <td>90.0100</td>\n",
       "      <td>86.289946</td>\n",
       "      <td>0.97150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open     High     Low  Close       EMA6      EMA12      EMA24   labels  \\\n",
       "In                                                                            \n",
       "0   75.83  77.8600  74.780  77.83  77.569071  77.924519  78.076373      NaN   \n",
       "1   77.01  79.6250  76.080  78.26  77.766479  77.976132  78.091063      NaN   \n",
       "2   77.90  79.7350  77.310  79.11  78.150342  78.150573  78.172578      NaN   \n",
       "3   79.67  81.3800  78.765  81.34  79.061673  78.641254  78.425972      NaN   \n",
       "4   81.37  83.5800  80.730  83.52  77.766479  77.976132  78.091063  83.5800   \n",
       "5   77.01  79.6250  76.080  78.26  77.766479  77.976132  78.091063      NaN   \n",
       "6   77.90  79.7350  77.310  79.11  78.150342  78.150573  78.172578      NaN   \n",
       "7   79.67  81.3800  78.765  81.34  79.061673  78.641254  78.425972      NaN   \n",
       "8   81.37  83.5800  80.730  83.52  80.335481  79.391830  78.833494      NaN   \n",
       "9   83.50  87.8350  82.730  87.68  78.150342  78.150573  78.172578  87.8350   \n",
       "10  77.90  79.7350  77.310  79.11  78.150342  78.150573  78.172578      NaN   \n",
       "11  79.67  81.3800  78.765  81.34  79.061673  78.641254  78.425972      NaN   \n",
       "12  81.37  83.5800  80.730  83.52  80.335481  79.391830  78.833494      NaN   \n",
       "13  83.50  87.8350  82.730  87.68  82.433915  80.666933  79.541215      NaN   \n",
       "14  88.32  89.4800  84.830  86.91  79.061673  78.641254  78.425972  89.4800   \n",
       "15  79.67  81.3800  78.765  81.34  79.061673  78.641254  78.425972      NaN   \n",
       "16  81.37  83.5800  80.730  83.52  80.335481  79.391830  78.833494      NaN   \n",
       "17  83.50  87.8350  82.730  87.68  82.433915  80.666933  79.541215      NaN   \n",
       "18  88.32  89.4800  84.830  86.91  83.712796  81.627405  80.130718      NaN   \n",
       "19  86.42  87.4502  84.500  84.59  80.335481  79.391830  78.833494  87.4502   \n",
       "20  81.37  83.5800  80.730  83.52  80.335481  79.391830  78.833494      NaN   \n",
       "21  83.50  87.8350  82.730  87.68  82.433915  80.666933  79.541215      NaN   \n",
       "22  88.32  89.4800  84.830  86.91  83.712796  81.627405  80.130718      NaN   \n",
       "23  86.42  87.4502  84.500  84.59  83.963426  82.083189  80.487460      NaN   \n",
       "24  84.59  90.0100  83.530  88.69  82.433915  80.666933  79.541215  90.0100   \n",
       "\n",
       "    prediction  CombinedVaderSentiment  \n",
       "In                                      \n",
       "0          NaN                 0.35190  \n",
       "1          NaN                 1.23185  \n",
       "2          NaN                 0.32155  \n",
       "3          NaN                 0.18315  \n",
       "4    83.286131                 1.23185  \n",
       "5          NaN                 1.23185  \n",
       "6          NaN                 0.32155  \n",
       "7          NaN                 0.18315  \n",
       "8          NaN                 0.99200  \n",
       "9    86.953958                 0.32155  \n",
       "10         NaN                 0.32155  \n",
       "11         NaN                 0.18315  \n",
       "12         NaN                 0.99200  \n",
       "13         NaN                 0.97150  \n",
       "14   88.904832                 0.18315  \n",
       "15         NaN                 0.18315  \n",
       "16         NaN                 0.99200  \n",
       "17         NaN                 0.97150  \n",
       "18         NaN                 0.00700  \n",
       "19   88.068110                 0.99200  \n",
       "20         NaN                 0.99200  \n",
       "21         NaN                 0.97150  \n",
       "22         NaN                 0.00700  \n",
       "23         NaN                -1.39380  \n",
       "24   86.289946                 0.97150  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers_preprocess import ReverseNormalization\n",
    "\n",
    "ReverseNormalization = ReverseNormalization()\n",
    "\n",
    "ReverseNormalization.fit(forecasts=forecast, labels=labels,\n",
    "                         x_valid=x_valid, x_valid_x=x_valid_x, window_size=window_size, debug=False,\n",
    "                         sentiment=sentiment,sentiment_type=sentiment_type)\n",
    "\n",
    "df = ReverseNormalization.transform()\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------> GetFinalDataframe\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>EMA6</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA24</th>\n",
       "      <th>labels</th>\n",
       "      <th>prediction</th>\n",
       "      <th>CombinedVaderSentiment</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.83</td>\n",
       "      <td>77.8600</td>\n",
       "      <td>74.780</td>\n",
       "      <td>77.83</td>\n",
       "      <td>77.569071</td>\n",
       "      <td>77.924519</td>\n",
       "      <td>78.076373</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.35190</td>\n",
       "      <td>2022-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.01</td>\n",
       "      <td>79.6250</td>\n",
       "      <td>76.080</td>\n",
       "      <td>78.26</td>\n",
       "      <td>77.766479</td>\n",
       "      <td>77.976132</td>\n",
       "      <td>78.091063</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>1.23185</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.90</td>\n",
       "      <td>79.7350</td>\n",
       "      <td>77.310</td>\n",
       "      <td>79.11</td>\n",
       "      <td>78.150342</td>\n",
       "      <td>78.150573</td>\n",
       "      <td>78.172578</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.32155</td>\n",
       "      <td>2022-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.67</td>\n",
       "      <td>81.3800</td>\n",
       "      <td>78.765</td>\n",
       "      <td>81.34</td>\n",
       "      <td>79.061673</td>\n",
       "      <td>78.641254</td>\n",
       "      <td>78.425972</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.18315</td>\n",
       "      <td>2022-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.37</td>\n",
       "      <td>83.5800</td>\n",
       "      <td>80.730</td>\n",
       "      <td>83.52</td>\n",
       "      <td>77.766479</td>\n",
       "      <td>77.976132</td>\n",
       "      <td>78.091063</td>\n",
       "      <td>83.58</td>\n",
       "      <td>83.286131</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2022-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77.01</td>\n",
       "      <td>79.6250</td>\n",
       "      <td>76.080</td>\n",
       "      <td>78.26</td>\n",
       "      <td>77.766479</td>\n",
       "      <td>77.976132</td>\n",
       "      <td>78.091063</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>1.23185</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77.90</td>\n",
       "      <td>79.7350</td>\n",
       "      <td>77.310</td>\n",
       "      <td>79.11</td>\n",
       "      <td>78.150342</td>\n",
       "      <td>78.150573</td>\n",
       "      <td>78.172578</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.32155</td>\n",
       "      <td>2022-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>79.67</td>\n",
       "      <td>81.3800</td>\n",
       "      <td>78.765</td>\n",
       "      <td>81.34</td>\n",
       "      <td>79.061673</td>\n",
       "      <td>78.641254</td>\n",
       "      <td>78.425972</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.18315</td>\n",
       "      <td>2022-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81.37</td>\n",
       "      <td>83.5800</td>\n",
       "      <td>80.730</td>\n",
       "      <td>83.52</td>\n",
       "      <td>80.335481</td>\n",
       "      <td>79.391830</td>\n",
       "      <td>78.833494</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>2022-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>83.50</td>\n",
       "      <td>87.8350</td>\n",
       "      <td>82.730</td>\n",
       "      <td>87.68</td>\n",
       "      <td>78.150342</td>\n",
       "      <td>78.150573</td>\n",
       "      <td>78.172578</td>\n",
       "      <td>87.835</td>\n",
       "      <td>86.953958</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2022-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>77.90</td>\n",
       "      <td>79.7350</td>\n",
       "      <td>77.310</td>\n",
       "      <td>79.11</td>\n",
       "      <td>78.150342</td>\n",
       "      <td>78.150573</td>\n",
       "      <td>78.172578</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.32155</td>\n",
       "      <td>2022-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>79.67</td>\n",
       "      <td>81.3800</td>\n",
       "      <td>78.765</td>\n",
       "      <td>81.34</td>\n",
       "      <td>79.061673</td>\n",
       "      <td>78.641254</td>\n",
       "      <td>78.425972</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.18315</td>\n",
       "      <td>2022-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>81.37</td>\n",
       "      <td>83.5800</td>\n",
       "      <td>80.730</td>\n",
       "      <td>83.52</td>\n",
       "      <td>80.335481</td>\n",
       "      <td>79.391830</td>\n",
       "      <td>78.833494</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>2022-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>83.50</td>\n",
       "      <td>87.8350</td>\n",
       "      <td>82.730</td>\n",
       "      <td>87.68</td>\n",
       "      <td>82.433915</td>\n",
       "      <td>80.666933</td>\n",
       "      <td>79.541215</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.97150</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>88.32</td>\n",
       "      <td>89.4800</td>\n",
       "      <td>84.830</td>\n",
       "      <td>86.91</td>\n",
       "      <td>79.061673</td>\n",
       "      <td>78.641254</td>\n",
       "      <td>78.425972</td>\n",
       "      <td>89.48</td>\n",
       "      <td>88.904832</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2022-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79.67</td>\n",
       "      <td>81.3800</td>\n",
       "      <td>78.765</td>\n",
       "      <td>81.34</td>\n",
       "      <td>79.061673</td>\n",
       "      <td>78.641254</td>\n",
       "      <td>78.425972</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.18315</td>\n",
       "      <td>2022-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>81.37</td>\n",
       "      <td>83.5800</td>\n",
       "      <td>80.730</td>\n",
       "      <td>83.52</td>\n",
       "      <td>80.335481</td>\n",
       "      <td>79.391830</td>\n",
       "      <td>78.833494</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>2022-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>83.50</td>\n",
       "      <td>87.8350</td>\n",
       "      <td>82.730</td>\n",
       "      <td>87.68</td>\n",
       "      <td>82.433915</td>\n",
       "      <td>80.666933</td>\n",
       "      <td>79.541215</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.97150</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>88.32</td>\n",
       "      <td>89.4800</td>\n",
       "      <td>84.830</td>\n",
       "      <td>86.91</td>\n",
       "      <td>83.712796</td>\n",
       "      <td>81.627405</td>\n",
       "      <td>80.130718</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.00700</td>\n",
       "      <td>2022-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86.42</td>\n",
       "      <td>87.4502</td>\n",
       "      <td>84.500</td>\n",
       "      <td>84.59</td>\n",
       "      <td>80.335481</td>\n",
       "      <td>79.391830</td>\n",
       "      <td>78.833494</td>\n",
       "      <td>87.4502</td>\n",
       "      <td>88.06811</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2022-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>81.37</td>\n",
       "      <td>83.5800</td>\n",
       "      <td>80.730</td>\n",
       "      <td>83.52</td>\n",
       "      <td>80.335481</td>\n",
       "      <td>79.391830</td>\n",
       "      <td>78.833494</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>2022-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83.50</td>\n",
       "      <td>87.8350</td>\n",
       "      <td>82.730</td>\n",
       "      <td>87.68</td>\n",
       "      <td>82.433915</td>\n",
       "      <td>80.666933</td>\n",
       "      <td>79.541215</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.97150</td>\n",
       "      <td>2022-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>88.32</td>\n",
       "      <td>89.4800</td>\n",
       "      <td>84.830</td>\n",
       "      <td>86.91</td>\n",
       "      <td>83.712796</td>\n",
       "      <td>81.627405</td>\n",
       "      <td>80.130718</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.00700</td>\n",
       "      <td>2022-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>86.42</td>\n",
       "      <td>87.4502</td>\n",
       "      <td>84.500</td>\n",
       "      <td>84.59</td>\n",
       "      <td>83.963426</td>\n",
       "      <td>82.083189</td>\n",
       "      <td>80.487460</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>-1.39380</td>\n",
       "      <td>2022-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>84.59</td>\n",
       "      <td>90.0100</td>\n",
       "      <td>83.530</td>\n",
       "      <td>88.69</td>\n",
       "      <td>82.433915</td>\n",
       "      <td>80.666933</td>\n",
       "      <td>79.541215</td>\n",
       "      <td>90.01</td>\n",
       "      <td>86.289946</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2022-04-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open     High     Low  Close       EMA6      EMA12      EMA24   labels  \\\n",
       "In                                                                            \n",
       "0   75.83  77.8600  74.780  77.83  77.569071  77.924519  78.076373       nn   \n",
       "1   77.01  79.6250  76.080  78.26  77.766479  77.976132  78.091063       nn   \n",
       "2   77.90  79.7350  77.310  79.11  78.150342  78.150573  78.172578       nn   \n",
       "3   79.67  81.3800  78.765  81.34  79.061673  78.641254  78.425972       nn   \n",
       "4   81.37  83.5800  80.730  83.52  77.766479  77.976132  78.091063    83.58   \n",
       "5   77.01  79.6250  76.080  78.26  77.766479  77.976132  78.091063       nn   \n",
       "6   77.90  79.7350  77.310  79.11  78.150342  78.150573  78.172578       nn   \n",
       "7   79.67  81.3800  78.765  81.34  79.061673  78.641254  78.425972       nn   \n",
       "8   81.37  83.5800  80.730  83.52  80.335481  79.391830  78.833494       nn   \n",
       "9   83.50  87.8350  82.730  87.68  78.150342  78.150573  78.172578   87.835   \n",
       "10  77.90  79.7350  77.310  79.11  78.150342  78.150573  78.172578       nn   \n",
       "11  79.67  81.3800  78.765  81.34  79.061673  78.641254  78.425972       nn   \n",
       "12  81.37  83.5800  80.730  83.52  80.335481  79.391830  78.833494       nn   \n",
       "13  83.50  87.8350  82.730  87.68  82.433915  80.666933  79.541215       nn   \n",
       "14  88.32  89.4800  84.830  86.91  79.061673  78.641254  78.425972    89.48   \n",
       "15  79.67  81.3800  78.765  81.34  79.061673  78.641254  78.425972       nn   \n",
       "16  81.37  83.5800  80.730  83.52  80.335481  79.391830  78.833494       nn   \n",
       "17  83.50  87.8350  82.730  87.68  82.433915  80.666933  79.541215       nn   \n",
       "18  88.32  89.4800  84.830  86.91  83.712796  81.627405  80.130718       nn   \n",
       "19  86.42  87.4502  84.500  84.59  80.335481  79.391830  78.833494  87.4502   \n",
       "20  81.37  83.5800  80.730  83.52  80.335481  79.391830  78.833494       nn   \n",
       "21  83.50  87.8350  82.730  87.68  82.433915  80.666933  79.541215       nn   \n",
       "22  88.32  89.4800  84.830  86.91  83.712796  81.627405  80.130718       nn   \n",
       "23  86.42  87.4502  84.500  84.59  83.963426  82.083189  80.487460       nn   \n",
       "24  84.59  90.0100  83.530  88.69  82.433915  80.666933  79.541215    90.01   \n",
       "\n",
       "   prediction  CombinedVaderSentiment    Datetime  \n",
       "In                                                 \n",
       "0          nn                 0.35190  2022-02-28  \n",
       "1          nn                 1.23185  2022-03-07  \n",
       "2          nn                 0.32155  2022-03-14  \n",
       "3          nn                 0.18315  2022-03-21  \n",
       "4   83.286131                 0.00000  2022-03-22  \n",
       "5          nn                 1.23185  2022-03-07  \n",
       "6          nn                 0.32155  2022-03-14  \n",
       "7          nn                 0.18315  2022-03-21  \n",
       "8          nn                 0.99200  2022-03-28  \n",
       "9   86.953958                 0.00000  2022-03-29  \n",
       "10         nn                 0.32155  2022-03-14  \n",
       "11         nn                 0.18315  2022-03-21  \n",
       "12         nn                 0.99200  2022-03-28  \n",
       "13         nn                 0.97150  2022-04-04  \n",
       "14  88.904832                 0.00000  2022-04-05  \n",
       "15         nn                 0.18315  2022-03-21  \n",
       "16         nn                 0.99200  2022-03-28  \n",
       "17         nn                 0.97150  2022-04-04  \n",
       "18         nn                 0.00700  2022-04-11  \n",
       "19   88.06811                 0.00000  2022-04-12  \n",
       "20         nn                 0.99200  2022-03-28  \n",
       "21         nn                 0.97150  2022-04-04  \n",
       "22         nn                 0.00700  2022-04-11  \n",
       "23         nn                -1.39380  2022-04-18  \n",
       "24  86.289946                 0.00000  2022-04-19  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from final_evaluation import GetFinalDataframe\n",
    "\n",
    "GetFinalDataframe = GetFinalDataframe()\n",
    "\n",
    "GetFinalDataframe.fit(dates=Dates,\n",
    "                      x_valid=x_valid,\n",
    "                      sentiment=sentiment,\n",
    "                      sentiment_type=sentiment_type)\n",
    "\n",
    "reversed_df = GetFinalDataframe.transform(df)\n",
    "reversed_df.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker: MRK\n",
      "\n",
      "Formations:  28\n",
      "period: 2022-02-28 - 2022-09-26\n",
      "Entry Candle:  Current Open\n",
      "\n",
      "Total Trades:  25\n",
      "Profit Trades:  18\n",
      "Loss Trades:  7\n",
      "\n",
      "Win Ratio: 72.0 %\n",
      "Loss Ratio: 28 %\n",
      "\n",
      "Trade nr with exact TP:  17\n",
      "Ratio of exact TP: 68.0 %\n",
      "\n",
      "Average profit per trade:  103\n",
      "\n",
      "Gross profit:  2580\n",
      "Gross loss:  -1236\n",
      "\n",
      "Net profit:  1344\n"
     ]
    }
   ],
   "source": [
    "from final_evaluation import GetModelPerformance\n",
    "#print(f\"Window size: {window_size} \\n\")\n",
    "print(f\"ticker: {str.upper(ticker)}\\n\")\n",
    "GetModelPerformance = GetModelPerformance()\n",
    "\n",
    "GetModelPerformance.fit(acceptance=0,\n",
    "                        penalization=0,\n",
    "                        entry_candle='Current Open',\n",
    "                        budget=10000,\n",
    "                        window_size=window_size,\n",
    "                        export_excel=True,\n",
    "                        excel_path = excel_reports,\n",
    "                        sentiment=sentiment)\n",
    "\n",
    "trades_df = GetModelPerformance.transform(reversed_df)\n",
    "#trades_df.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = 1\n",
    "budget = 10000\n",
    "entry_candle = 'Current Open'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trade:  1\n",
      "Window size:  5\n",
      "Period: 2022-02-14 - 2022-03-07\n",
      "\n",
      "Budget:  10000\n",
      "\n",
      "Entry price:  77.9\n",
      "Label (target):  79.74\n",
      "Model prediction:  79.17\n",
      "Market Change: 1.27 $\n",
      "Profit: 163.03 $\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x621 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>EMA6</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA24</th>\n",
       "      <th>labels</th>\n",
       "      <th>prediction</th>\n",
       "      <th>CombinedVaderSentiment</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>profit</th>\n",
       "      <th>trade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.629997</td>\n",
       "      <td>78.190002</td>\n",
       "      <td>75.110001</td>\n",
       "      <td>76.370003</td>\n",
       "      <td>77.909017</td>\n",
       "      <td>78.206483</td>\n",
       "      <td>78.080399</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.87045</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.273226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.459999</td>\n",
       "      <td>77.290001</td>\n",
       "      <td>72.879997</td>\n",
       "      <td>76.320000</td>\n",
       "      <td>77.455012</td>\n",
       "      <td>77.916255</td>\n",
       "      <td>77.939567</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>2022-02-21</td>\n",
       "      <td>1.273226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.830002</td>\n",
       "      <td>77.860001</td>\n",
       "      <td>74.779999</td>\n",
       "      <td>77.830002</td>\n",
       "      <td>77.562152</td>\n",
       "      <td>77.902985</td>\n",
       "      <td>77.930802</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>1.15980</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>1.273226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.010002</td>\n",
       "      <td>79.629997</td>\n",
       "      <td>76.080002</td>\n",
       "      <td>78.260002</td>\n",
       "      <td>77.761538</td>\n",
       "      <td>77.957911</td>\n",
       "      <td>77.957138</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>1.273226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.900002</td>\n",
       "      <td>79.739998</td>\n",
       "      <td>77.309998</td>\n",
       "      <td>79.110001</td>\n",
       "      <td>77.455012</td>\n",
       "      <td>77.916255</td>\n",
       "      <td>77.939567</td>\n",
       "      <td>79.739998</td>\n",
       "      <td>79.173227</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2022-03-08</td>\n",
       "      <td>1.273226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open       High        Low      Close       EMA6      EMA12  \\\n",
       "In                                                                     \n",
       "0   76.629997  78.190002  75.110001  76.370003  77.909017  78.206483   \n",
       "1   76.459999  77.290001  72.879997  76.320000  77.455012  77.916255   \n",
       "2   75.830002  77.860001  74.779999  77.830002  77.562152  77.902985   \n",
       "3   77.010002  79.629997  76.080002  78.260002  77.761538  77.957911   \n",
       "4   77.900002  79.739998  77.309998  79.110001  77.455012  77.916255   \n",
       "\n",
       "        EMA24     labels prediction  CombinedVaderSentiment    Datetime  \\\n",
       "In                                                                        \n",
       "0   78.080399         nn         nn                 0.87045  2022-02-14   \n",
       "1   77.939567         nn         nn                 0.99750  2022-02-21   \n",
       "2   77.930802         nn         nn                 1.15980  2022-02-28   \n",
       "3   77.957138         nn         nn                 0.99800  2022-03-07   \n",
       "4   77.939567  79.739998  79.173227                 0.00000  2022-03-08   \n",
       "\n",
       "      profit trade  \n",
       "In                  \n",
       "0   1.273226     1  \n",
       "1   1.273226     1  \n",
       "2   1.273226     1  \n",
       "3   1.273226     1  \n",
       "4   1.273226     1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trade = 4\n",
    "from plotting import PlotTrade\n",
    "\n",
    "df = PlotTrade(trade=trade,trades_df=trades_df,window_size=window_size,entry_candle=entry_candle,budget=budget,sentiment=sentiment)\n",
    "trade += 1\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------> GetPerformanceReport completed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>EMA6</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA24</th>\n",
       "      <th>labels</th>\n",
       "      <th>prediction</th>\n",
       "      <th>CombinedVaderSentiment</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>profit</th>\n",
       "      <th>trade</th>\n",
       "      <th>Entry</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.629997</td>\n",
       "      <td>78.190002</td>\n",
       "      <td>75.110001</td>\n",
       "      <td>76.370003</td>\n",
       "      <td>77.909017</td>\n",
       "      <td>78.206483</td>\n",
       "      <td>78.080399</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.87045</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>1.273226</td>\n",
       "      <td>1</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.459999</td>\n",
       "      <td>77.290001</td>\n",
       "      <td>72.879997</td>\n",
       "      <td>76.320000</td>\n",
       "      <td>77.455012</td>\n",
       "      <td>77.916255</td>\n",
       "      <td>77.939567</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>2022-02-21</td>\n",
       "      <td>1.273226</td>\n",
       "      <td>1</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.830002</td>\n",
       "      <td>77.860001</td>\n",
       "      <td>74.779999</td>\n",
       "      <td>77.830002</td>\n",
       "      <td>77.562152</td>\n",
       "      <td>77.902985</td>\n",
       "      <td>77.930802</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>1.15980</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>1.273226</td>\n",
       "      <td>1</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.010002</td>\n",
       "      <td>79.629997</td>\n",
       "      <td>76.080002</td>\n",
       "      <td>78.260002</td>\n",
       "      <td>77.761538</td>\n",
       "      <td>77.957911</td>\n",
       "      <td>77.957138</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>1.273226</td>\n",
       "      <td>1</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.900002</td>\n",
       "      <td>79.739998</td>\n",
       "      <td>77.309998</td>\n",
       "      <td>79.110001</td>\n",
       "      <td>77.455012</td>\n",
       "      <td>77.916255</td>\n",
       "      <td>77.939567</td>\n",
       "      <td>79.739998</td>\n",
       "      <td>79.173227</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2022-03-08</td>\n",
       "      <td>1.273226</td>\n",
       "      <td>1</td>\n",
       "      <td>77.900002</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>91.809998</td>\n",
       "      <td>92.220001</td>\n",
       "      <td>89.070000</td>\n",
       "      <td>89.260002</td>\n",
       "      <td>90.332518</td>\n",
       "      <td>90.065515</td>\n",
       "      <td>88.255073</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>2022-08-22</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>23</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>88.830002</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>85.160004</td>\n",
       "      <td>86.230003</td>\n",
       "      <td>89.160371</td>\n",
       "      <td>89.475436</td>\n",
       "      <td>88.093068</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.99250</td>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>23</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>86.580002</td>\n",
       "      <td>88.169998</td>\n",
       "      <td>85.070000</td>\n",
       "      <td>87.339996</td>\n",
       "      <td>88.640264</td>\n",
       "      <td>89.146907</td>\n",
       "      <td>88.032822</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.98600</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>23</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>88.129997</td>\n",
       "      <td>89.169998</td>\n",
       "      <td>86.110001</td>\n",
       "      <td>87.720001</td>\n",
       "      <td>88.377332</td>\n",
       "      <td>88.927383</td>\n",
       "      <td>88.007796</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>23</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>86.849998</td>\n",
       "      <td>88.150002</td>\n",
       "      <td>84.519997</td>\n",
       "      <td>86.779999</td>\n",
       "      <td>88.377332</td>\n",
       "      <td>88.927383</td>\n",
       "      <td>88.007796</td>\n",
       "      <td>88.150002</td>\n",
       "      <td>89.508142</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>23</td>\n",
       "      <td>86.849998</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open       High        Low      Close       EMA6      EMA12  \\\n",
       "0    76.629997  78.190002  75.110001  76.370003  77.909017  78.206483   \n",
       "1    76.459999  77.290001  72.879997  76.320000  77.455012  77.916255   \n",
       "2    75.830002  77.860001  74.779999  77.830002  77.562152  77.902985   \n",
       "3    77.010002  79.629997  76.080002  78.260002  77.761538  77.957911   \n",
       "4    77.900002  79.739998  77.309998  79.110001  77.455012  77.916255   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "110  91.809998  92.220001  89.070000  89.260002  90.332518  90.065515   \n",
       "111  88.830002  89.000000  85.160004  86.230003  89.160371  89.475436   \n",
       "112  86.580002  88.169998  85.070000  87.339996  88.640264  89.146907   \n",
       "113  88.129997  89.169998  86.110001  87.720001  88.377332  88.927383   \n",
       "114  86.849998  88.150002  84.519997  86.779999  88.377332  88.927383   \n",
       "\n",
       "         EMA24     labels prediction  CombinedVaderSentiment    Datetime  \\\n",
       "0    78.080399         nn         nn                 0.87045  2022-02-14   \n",
       "1    77.939567         nn         nn                 0.99750  2022-02-21   \n",
       "2    77.930802         nn         nn                 1.15980  2022-02-28   \n",
       "3    77.957138         nn         nn                 0.99800  2022-03-07   \n",
       "4    77.939567  79.739998  79.173227                 0.00000  2022-03-08   \n",
       "..         ...        ...        ...                     ...         ...   \n",
       "110  88.255073         nn         nn                 0.99000  2022-08-22   \n",
       "111  88.093068         nn         nn                 0.99250  2022-08-29   \n",
       "112  88.032822         nn         nn                 0.98600  2022-09-05   \n",
       "113  88.007796         nn         nn                 0.99300  2022-09-12   \n",
       "114  88.007796  88.150002  89.508142                 0.00000  2022-09-13   \n",
       "\n",
       "       profit  trade      Entry Performance  \n",
       "0    1.273226      1         nn          nn  \n",
       "1    1.273226      1         nn          nn  \n",
       "2    1.273226      1         nn          nn  \n",
       "3    1.273226      1         nn          nn  \n",
       "4    1.273226      1  77.900002       163.0  \n",
       "..        ...    ...        ...         ...  \n",
       "110 -0.070000     23         nn          nn  \n",
       "111 -0.070000     23         nn          nn  \n",
       "112 -0.070000     23         nn          nn  \n",
       "113 -0.070000     23         nn          nn  \n",
       "114 -0.070000     23  86.849998        -8.0  \n",
       "\n",
       "[115 rows x 15 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from final_evaluation import GetPerformanceReport\n",
    "\n",
    "GetPerformanceReport = GetPerformanceReport()\n",
    "\n",
    "GetPerformanceReport.fit(entry_candle=\"Current Open\",\n",
    "                        budget=10000,\n",
    "                        window_size=window_size,\n",
    "                        export_excel=True,\n",
    "                        excel_path = excel_reports)\n",
    "\n",
    "trades_df_final = GetPerformanceReport.transform(trades_df)\n",
    "trades_df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>EMA6</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA24</th>\n",
       "      <th>CombinedVaderSentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>88.830002</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>85.160004</td>\n",
       "      <td>86.230003</td>\n",
       "      <td>89.160371</td>\n",
       "      <td>89.475437</td>\n",
       "      <td>88.086169</td>\n",
       "      <td>0.726783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>86.580002</td>\n",
       "      <td>88.169998</td>\n",
       "      <td>85.070000</td>\n",
       "      <td>87.339996</td>\n",
       "      <td>88.640264</td>\n",
       "      <td>89.146907</td>\n",
       "      <td>88.026475</td>\n",
       "      <td>0.523185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>88.129997</td>\n",
       "      <td>89.169998</td>\n",
       "      <td>86.110001</td>\n",
       "      <td>87.720001</td>\n",
       "      <td>88.377332</td>\n",
       "      <td>88.927383</td>\n",
       "      <td>88.001957</td>\n",
       "      <td>0.552186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>86.849998</td>\n",
       "      <td>88.150002</td>\n",
       "      <td>84.519997</td>\n",
       "      <td>86.779999</td>\n",
       "      <td>87.920951</td>\n",
       "      <td>88.597016</td>\n",
       "      <td>87.904200</td>\n",
       "      <td>0.922004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>86.120003</td>\n",
       "      <td>87.629997</td>\n",
       "      <td>85.290001</td>\n",
       "      <td>86.120003</td>\n",
       "      <td>87.406394</td>\n",
       "      <td>88.215937</td>\n",
       "      <td>87.761464</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close       EMA6  \\\n",
       "0 2022-08-29  88.830002  89.000000  85.160004  86.230003  89.160371   \n",
       "1 2022-09-05  86.580002  88.169998  85.070000  87.339996  88.640264   \n",
       "2 2022-09-12  88.129997  89.169998  86.110001  87.720001  88.377332   \n",
       "3 2022-09-19  86.849998  88.150002  84.519997  86.779999  87.920951   \n",
       "4 2022-09-26  86.120003  87.629997  85.290001  86.120003  87.406394   \n",
       "\n",
       "       EMA12      EMA24  CombinedVaderSentiment  \n",
       "0  89.475437  88.086169                0.726783  \n",
       "1  89.146907  88.026475                0.523185  \n",
       "2  88.927383  88.001957                0.552186  \n",
       "3  88.597016  87.904200                0.922004  \n",
       "4  88.215937  87.761464                0.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from final_evaluation import MakeSinglePrediction\n",
    "\n",
    "model_name = f'{saved_models}/{str.upper(ticker)}_{formation_window}_{target_window}_{window_size}_{split_ratio}_{period}_{sentiment}_{start_date}_{end_date}.h5'\n",
    "\n",
    "MakeSinglePrediction = MakeSinglePrediction()\n",
    "\n",
    "fit_output = MakeSinglePrediction.fit(\n",
    "                        model_name=model_name,\n",
    "                        form_window=formation_window,\n",
    "                        ticker=ticker,\n",
    "                        start_date=\"2021-03-18\",\n",
    "                        end_date=\"2022-10-02\",\n",
    "                        interval='1wk',\n",
    "                        progress=False,\n",
    "                        condition=False,\n",
    "                        timeperiod1=6,\n",
    "                        timeperiod2=12,\n",
    "                        timeperiod3=24,\n",
    "                        debug=False,\n",
    "                        budget=10000,\n",
    "                        penalization=0,\n",
    "                        acceptance=0,\n",
    "                        entry_candle='Current Open',\n",
    "                        news_df=news_df,\n",
    "                        sentiment=sentiment,\n",
    "                        sentiment_type = sentiment_type,\n",
    "                        sentiment_aggr = aggr_function)\n",
    "\n",
    "#fit method outputs tuple, get only trade formation out of tuple\n",
    "trade_formation = fit_output[1]\n",
    "final_trade_formation = trade_formation.head(24)\n",
    "final_trade_formation\n",
    "###IMPORTANT!!!!\n",
    "#trade_formation dataframe must be checked before transformation, sometimes df pulled via yahoo finance \n",
    "# is shifted, and trade formation does not have entire formation in itself. in this case there must \n",
    "# be changed end_date in fit method\n",
    "final_trade_formation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ticker:  mrk\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      "Entry candle (Current Open)\n",
      "\n",
      "Budget:  10000\n",
      "\n",
      "Entry price:  86.12\n",
      "Prediction:  87.51\n",
      "Expected Market move:  1.39\n",
      "Expected Profit:  160.98\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x862.5 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make prediction\n",
    "MakeSinglePrediction.transform(final_trade_formation)\n",
    "\n",
    "#PLot current chart and sentiment\n",
    "from plotting import PlotCurrentFormation\n",
    "\n",
    "PlotCurrentFormation(final_trade_formation,sentiment=sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Record Predictions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>prediction</th>\n",
       "      <th>real market move</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STNSE</td>\n",
       "      <td>21.8.2022</td>\n",
       "      <td>12.97 (should be penalized by 2 - 10.97)</td>\n",
       "      <td>pending</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MRK</td>\n",
       "      <td>27.8.2022</td>\n",
       "      <td>93.23</td>\n",
       "      <td>failed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MRK</td>\n",
       "      <td>11.9.2022</td>\n",
       "      <td>91.31</td>\n",
       "      <td>pending</td>\n",
       "      <td>.\\Saved models/MRK_24_4_25_0.8_1wk_True_2020-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MRK</td>\n",
       "      <td>24.9.2022</td>\n",
       "      <td>91.8</td>\n",
       "      <td>pending</td>\n",
       "      <td>.\\Saved models/MRK_24_4_25_0.8_1wk_True_2020-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLB</td>\n",
       "      <td>21.8.2022</td>\n",
       "      <td>18.6</td>\n",
       "      <td>succesful - 12.9.2022</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLB</td>\n",
       "      <td>04.9.2022</td>\n",
       "      <td>18.08</td>\n",
       "      <td>succesful - 9.9.2022</td>\n",
       "      <td>.\\Saved models/MRK_24_4_25_0.8_1wk_True_2020-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       Date                                prediction  \\\n",
       "0  STNSE  21.8.2022  12.97 (should be penalized by 2 - 10.97)   \n",
       "0    MRK  27.8.2022                                     93.23   \n",
       "0    MRK  11.9.2022                                     91.31   \n",
       "0    MRK  24.9.2022                                      91.8   \n",
       "0    CLB  21.8.2022                                      18.6   \n",
       "0    CLB  04.9.2022                                     18.08   \n",
       "\n",
       "        real market move                                              model  \n",
       "0                pending                                                     \n",
       "0                 failed                                                     \n",
       "0                pending  .\\Saved models/MRK_24_4_25_0.8_1wk_True_2020-0...  \n",
       "0                pending  .\\Saved models/MRK_24_4_25_0.8_1wk_True_2020-0...  \n",
       "0  succesful - 12.9.2022                                                     \n",
       "0   succesful - 9.9.2022  .\\Saved models/MRK_24_4_25_0.8_1wk_True_2020-0...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "#List all predictions\n",
    "dicti_prediction1 = {'ticker':['STNSE'],'Date':['21.8.2022'],'prediction':['12.97 (should be penalized by 2 - 10.97)'],'real market move':['pending'],'model':[\"\"]}\n",
    "dicti_prediction2 = {'ticker':['CLB'],'Date':['21.8.2022'],'prediction':['18.6'],'real market move':['succesful - 12.9.2022'],'model':[\"\"]}\n",
    "dicti_prediction3 = {'ticker':['MRK'],'Date':['27.8.2022'],'prediction':['93.23'],'real market move':['failed'],'model':[\"\"]}\n",
    "dicti_prediction4 = {'ticker':['CLB'],'Date':['04.9.2022'],'prediction':['18.08'],'real market move':['succesful - 9.9.2022'],'model':[model_name]}\n",
    "dicti_prediction5 = {'ticker':['MRK'],'Date':['11.9.2022'],'prediction':['91.31'],'real market move':['pending'],'model':[model_name]}\n",
    "dicti_prediction6 = {'ticker':['MRK'],'Date':['24.9.2022'],'prediction':['91.8'],'real market move':['pending'],'model':[model_name]}\n",
    "\n",
    "trades_tuple = (dicti_prediction1,dicti_prediction2,dicti_prediction3,dicti_prediction4,dicti_prediction5,dicti_prediction6)\n",
    "for item in trades_tuple:\n",
    "    df_pred = pd.DataFrame(item)\n",
    "    final_df = final_df.append(df_pred)\n",
    "    final_df = final_df.sort_values('ticker',ascending=False)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('04_stockprediction': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ae9b00e5548af57dc5d4c583df0ad518b3d501960f1be5c69ca4a560e00ae05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
