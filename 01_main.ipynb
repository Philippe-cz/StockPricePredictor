{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from typing import Any, Dict, Iterable, Iterator, List, Optional, Tuple, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import PullData\n",
    "\n",
    "window_size = 25\n",
    "formation_window = 24\n",
    "target_window = 4\n",
    "\n",
    "GetData = PullData()\n",
    "\n",
    "GetData.fit(ticker='nvda',\n",
    "            start_date='1980-01-01',\n",
    "            end_date='2022-08-04',\n",
    "            interval='1wk',\n",
    "            progress=False,\n",
    "            condition=False,\n",
    "            form_window=formation_window,\n",
    "            target_window=target_window,\n",
    "            timeperiod1=6,\n",
    "            timeperiod2=12,\n",
    "            timeperiod3=24,\n",
    "            export_excel=True\n",
    "            )\n",
    "\n",
    "data_prep = GetData.transform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial length of dataframe:  30025\n",
      "Nr of formations:  1201\n",
      "New length of dataframe:  30025\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from transformers import NormalizeData\n",
    "\n",
    "NormalizeData = NormalizeData()\n",
    "\n",
    "NormalizeData.fit(window_size=25, shuffle=False, debug=False)\n",
    "\n",
    "data_normalized, Dates = NormalizeData.transform(data_prep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df:   30025\n",
      "total windows in dataset:  1201.0\n",
      "\n",
      "total windows of 80.0% train set: 961.0 \n",
      "total windows of 20% valid set: 240.0 \n",
      "\n",
      "x_train window 961.0\n",
      "x_valid window 240.0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from training import SplitData\n",
    "\n",
    "SplitData = SplitData()\n",
    "\n",
    "SplitData.fit(split_ratio=0.8, window_size=25, dates=Dates, debug=True)\n",
    "\n",
    "x_train, x_valid, x_train_x, x_valid_x = SplitData.transform(data_normalized)\n",
    "\n",
    "# print(data_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, None), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from training import GetTensoredDataset\n",
    "\n",
    "GetTensoredDataset = GetTensoredDataset()\n",
    "\n",
    "GetTensoredDataset.fit(window_size=25, batch_size=16, train=True, debug=False)\n",
    "\n",
    "x_train_tensors, _ = GetTensoredDataset.transform(x_train)\n",
    "\n",
    "x_train_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 24, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from training import GetTensoredDataset\n",
    "\n",
    "GetTensoredValidDataset = GetTensoredDataset()\n",
    "\n",
    "GetTensoredValidDataset.fit(\n",
    "    window_size=25, batch_size=4, train=False, debug=False)\n",
    "\n",
    "x_valid_tensors, labels = GetTensoredValidDataset.transform(x_valid)\n",
    "x_valid_tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Training</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=6, mode='min', restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=10e-15,\n",
    "                              verbose=1)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss',\n",
    "                                   filepath='./nvda_80_model_checkpoint_recent.h5',\n",
    "                                   save_best_only=True)\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr, model_checkpoint]\n",
    "\n",
    "\n",
    "def sign_penalty(y_true, y_pred):\n",
    "    penalty = 100.\n",
    "    loss = tf.where(tf.less(y_true*y_pred, 0),\n",
    "                    penalty * tf.square(y_true-y_pred),\n",
    "                    tf.square(y_true - y_pred)\n",
    "                    )\n",
    "\n",
    "    return(tf.reduce_mean(loss, axis=-1))\n",
    "\n",
    "\n",
    "tf.keras.losses.sign_penalty = sign_penalty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(7788)\n",
    "\n",
    "# model = tf.keras.models.Sequential([\n",
    "\n",
    "#     tf.keras.layers.Conv1D(filters=256, kernel_size=10,\n",
    "#                       strides=1, padding=\"same\",\n",
    "#                       activation=tf.nn.selu,\n",
    "#                       input_shape=[None, 7]),\n",
    "# #     tf.keras.layers.Conv1D(filters=512, kernel_size=10,\n",
    "# #                       strides=1, padding=\"same\",\n",
    "# #                       activation=tf.nn.selu,\n",
    "# #                       input_shape=[None, 7]),\n",
    "\n",
    "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "#     # tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(1024, activation=tf.nn.selu),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(1024, activation=tf.nn.selu),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(1024, activation=tf.nn.selu),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(1024, activation=tf.nn.selu),\n",
    "#     #tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(16, activation=tf.nn.selu),\n",
    "#     tf.keras.layers.Dense(16, activation=tf.nn.selu),\n",
    "#     tf.keras.layers.Dense(4, activation=tf.nn.selu),\n",
    "#     tf.keras.layers.Dense(3, activation=tf.nn.selu), #4\n",
    "#     tf.keras.layers.Dense(1,activation=tf.nn.relu),\n",
    "# ])\n",
    "\n",
    "# #optimizer1 = tf.keras.optimizers.SGD(learning_rate=10e-7, momentum=0.9)\n",
    "# #optimizer2 = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "# #optimizer3 = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False)\n",
    "# #optimizer4 = tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95, epsilon=1e-07, name='Adadelta')\n",
    "\n",
    "# optimizer5 = tf.keras.optimizers.Adagrad(learning_rate=0.0001, initial_accumulator_value=0.1, epsilon=1e-07,name='Adagrad')\n",
    "\n",
    "\n",
    "# model.compile(loss=sign_penalty,\n",
    "#               optimizer=optimizer5,\n",
    "#               )\n",
    "\n",
    "# model.fit(train_set, epochs=120,callbacks=[callbacks],validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "61/61 [==============================] - 8s 65ms/step - loss: 0.0369 - val_loss: 0.0280 - lr: 0.0100\n",
      "Epoch 2/120\n",
      "61/61 [==============================] - 2s 26ms/step - loss: 0.0292 - val_loss: 0.0260 - lr: 0.0100\n",
      "Epoch 3/120\n",
      "61/61 [==============================] - 1s 22ms/step - loss: 0.0272 - val_loss: 0.0247 - lr: 0.0100\n",
      "Epoch 4/120\n",
      "61/61 [==============================] - 1s 21ms/step - loss: 0.0259 - val_loss: 0.0238 - lr: 0.0100\n",
      "Epoch 5/120\n",
      "61/61 [==============================] - 1s 22ms/step - loss: 0.0248 - val_loss: 0.0228 - lr: 0.0100\n",
      "Epoch 6/120\n",
      "61/61 [==============================] - 1s 21ms/step - loss: 0.0239 - val_loss: 0.0221 - lr: 0.0100\n",
      "Epoch 7/120\n",
      "61/61 [==============================] - 1s 20ms/step - loss: 0.0232 - val_loss: 0.0218 - lr: 0.0100\n",
      "Epoch 8/120\n",
      "61/61 [==============================] - 1s 23ms/step - loss: 0.0226 - val_loss: 0.0212 - lr: 0.0100\n",
      "Epoch 9/120\n",
      "61/61 [==============================] - 1s 22ms/step - loss: 0.0221 - val_loss: 0.0209 - lr: 0.0100\n",
      "Epoch 10/120\n",
      "61/61 [==============================] - 1s 22ms/step - loss: 0.0217 - val_loss: 0.0205 - lr: 0.0100\n",
      "Epoch 11/120\n",
      "61/61 [==============================] - 1s 20ms/step - loss: 0.0214 - val_loss: 0.0203 - lr: 0.0100\n",
      "Epoch 12/120\n",
      "61/61 [==============================] - 1s 21ms/step - loss: 0.0211 - val_loss: 0.0202 - lr: 0.0100\n",
      "Epoch 13/120\n",
      "61/61 [==============================] - 1s 23ms/step - loss: 0.0209 - val_loss: 0.0199 - lr: 0.0100\n",
      "Epoch 14/120\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.0207 - val_loss: 0.0197 - lr: 0.0100\n",
      "Epoch 15/120\n",
      "61/61 [==============================] - 2s 36ms/step - loss: 0.0205 - val_loss: 0.0195 - lr: 0.0100\n",
      "Epoch 16/120\n",
      "61/61 [==============================] - 2s 36ms/step - loss: 0.0203 - val_loss: 0.0193 - lr: 0.0100\n",
      "Epoch 17/120\n",
      "61/61 [==============================] - 1s 24ms/step - loss: 0.0201 - val_loss: 0.0191 - lr: 0.0100\n",
      "Epoch 18/120\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.0200 - val_loss: 0.0190 - lr: 0.0100\n",
      "Epoch 19/120\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.0199 - val_loss: 0.0188 - lr: 0.0100\n",
      "Epoch 20/120\n",
      "61/61 [==============================] - 2s 34ms/step - loss: 0.0198 - val_loss: 0.0187 - lr: 0.0100\n",
      "Epoch 21/120\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 0.0197 - val_loss: 0.0186 - lr: 0.0100\n",
      "Epoch 22/120\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.0196 - val_loss: 0.0185 - lr: 0.0100\n",
      "Epoch 23/120\n",
      "61/61 [==============================] - 2s 26ms/step - loss: 0.0195 - val_loss: 0.0183 - lr: 0.0100\n",
      "Epoch 24/120\n",
      "61/61 [==============================] - 1s 24ms/step - loss: 0.0194 - val_loss: 0.0182 - lr: 0.0100\n",
      "Epoch 25/120\n",
      "61/61 [==============================] - 1s 23ms/step - loss: 0.0193 - val_loss: 0.0181 - lr: 0.0100\n",
      "Epoch 26/120\n",
      "61/61 [==============================] - 1s 22ms/step - loss: 0.0193 - val_loss: 0.0180 - lr: 0.0100\n",
      "Epoch 27/120\n",
      "61/61 [==============================] - 1s 22ms/step - loss: 0.0192 - val_loss: 0.0179 - lr: 0.0100\n",
      "Epoch 28/120\n",
      "61/61 [==============================] - 2s 26ms/step - loss: 0.0191 - val_loss: 0.0178 - lr: 0.0100\n",
      "Epoch 29/120\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.0191 - val_loss: 0.0177 - lr: 0.0100\n",
      "Epoch 30/120\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.0190 - val_loss: 0.0176 - lr: 0.0100\n",
      "Epoch 31/120\n",
      "61/61 [==============================] - 2s 26ms/step - loss: 0.0189 - val_loss: 0.0175 - lr: 0.0100\n",
      "Epoch 32/120\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.0189 - val_loss: 0.0174 - lr: 0.0100\n",
      "Epoch 33/120\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.0188 - val_loss: 0.0173 - lr: 0.0100\n",
      "Epoch 34/120\n",
      "61/61 [==============================] - 1s 24ms/step - loss: 0.0188 - val_loss: 0.0172 - lr: 0.0100\n",
      "Epoch 35/120\n",
      "61/61 [==============================] - 2s 25ms/step - loss: 0.0187 - val_loss: 0.0171 - lr: 0.0100\n",
      "Epoch 36/120\n",
      "61/61 [==============================] - 1s 24ms/step - loss: 0.0187 - val_loss: 0.0170 - lr: 0.0100\n",
      "Epoch 37/120\n",
      "61/61 [==============================] - 1s 23ms/step - loss: 0.0186 - val_loss: 0.0170 - lr: 0.0100\n",
      "Epoch 38/120\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.0186 - val_loss: 0.0169 - lr: 0.0100\n",
      "Epoch 39/120\n",
      "61/61 [==============================] - 1s 22ms/step - loss: 0.0185 - val_loss: 0.0168 - lr: 0.0100\n",
      "Epoch 40/120\n",
      "61/61 [==============================] - 2s 26ms/step - loss: 0.0185 - val_loss: 0.0167 - lr: 0.0100\n",
      "Epoch 41/120\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.0184 - val_loss: 0.0166 - lr: 0.0100\n",
      "Epoch 42/120\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.0184 - val_loss: 0.0166 - lr: 0.0100\n",
      "Epoch 43/120\n",
      "61/61 [==============================] - 2s 35ms/step - loss: 0.0183 - val_loss: 0.0165 - lr: 0.0100\n",
      "Epoch 44/120\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.0183 - val_loss: 0.0165 - lr: 0.0100\n",
      "Epoch 45/120\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0182\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "61/61 [==============================] - 2s 34ms/step - loss: 0.0182 - val_loss: 0.0164 - lr: 0.0100\n",
      "Epoch 46/120\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.0198 - val_loss: 0.0150 - lr: 0.0020\n",
      "Epoch 47/120\n",
      "61/61 [==============================] - 2s 36ms/step - loss: 0.0184 - val_loss: 0.0152 - lr: 0.0020\n",
      "Epoch 48/120\n",
      "59/61 [============================>.] - ETA: 0s - loss: 0.0185\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.0183 - val_loss: 0.0152 - lr: 0.0020\n",
      "Epoch 49/120\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.0181 - val_loss: 0.0154 - lr: 4.0000e-04\n",
      "Epoch 50/120\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0181\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.0181 - val_loss: 0.0155 - lr: 4.0000e-04\n",
      "Epoch 51/120\n",
      "61/61 [==============================] - 1s 23ms/step - loss: 0.0180 - val_loss: 0.0155 - lr: 8.0000e-05\n",
      "Epoch 52/120\n",
      "59/61 [============================>.] - ETA: 0s - loss: 0.0182\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "61/61 [==============================] - 1s 23ms/step - loss: 0.0180 - val_loss: 0.0155 - lr: 8.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c8f23ac2e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(7788)\n",
    "np.random.seed(7788)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters=8, kernel_size=1,\n",
    "                           strides=1, padding=\"same\",\n",
    "                           activation=tf.nn.selu,\n",
    "                           input_shape=[None, 7]),\n",
    "    tf.keras.layers.Conv1D(filters=16, kernel_size=1,\n",
    "                           strides=1, padding=\"same\",\n",
    "                           activation=tf.nn.elu,\n",
    "                           #input_shape=[None, 7]\n",
    "                           ),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=10,\n",
    "                           strides=1, padding=\"same\",\n",
    "                           activation=tf.nn.selu,\n",
    "                           #input_shape=[None, 7]\n",
    "                           ),\n",
    "    #     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(3, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(3)),\n",
    "    tf.keras.layers.Dense(3, activation=tf.nn.selu),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.selu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.relu),\n",
    "])\n",
    "\n",
    "optimizer2 = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0009, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "optimizer5 = tf.keras.optimizers.Adagrad(\n",
    "    learning_rate=0.01, initial_accumulator_value=4, epsilon=1e-07, name='Adagrad')\n",
    "\n",
    "model.compile(loss=sign_penalty,\n",
    "              optimizer=optimizer5,\n",
    "              )\n",
    "\n",
    "model.fit(x_train_tensors, epochs=120, callbacks=[\n",
    "          callbacks], validation_data=x_valid_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 2s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9225807 , 0.86792785], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_forecast(model, series, window_size, debug):\n",
    "    \"\"\"\n",
    "    Get model, data and window size as an input. \n",
    "    Make prediction window is subtracted by 1, since we do not need label in window, \n",
    "    label value is skipped\n",
    "    \"\"\"\n",
    "    c = 0\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size-1, shift=window_size, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "\n",
    "    if debug == True:\n",
    "        # This block of code will print out data on which is made prediction\n",
    "        for item in ds:\n",
    "            c += 1\n",
    "            if c < 3:\n",
    "                print(\"\\n\"+str(c) + \" prediction:\\n \", item)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    ds = ds.batch(1).prefetch(1)\n",
    "    forecast = model.predict(ds)\n",
    "    forecast2 = np.squeeze(forecast)\n",
    "    return forecast2\n",
    "\n",
    "\n",
    "forecast = model_forecast(model, x_valid, window_size=window_size, debug=False)\n",
    "forecast[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Raw prediction:  [[0.9225807]]\n"
     ]
    }
   ],
   "source": [
    "pr = x_valid.iloc[:24, :].to_numpy()\n",
    "pr = np.array([pr])\n",
    "pr = np.array([pr])\n",
    "pred = tf.data.Dataset.from_tensor_slices(pr)\n",
    "predict = model.predict(pred)\n",
    "print(\"Raw prediction: \", predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6000, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ReverseNormalization\n",
    "\n",
    "ReverseNormalization = ReverseNormalization()\n",
    "\n",
    "ReverseNormalization.fit(forecasts=forecast, labels=labels,\n",
    "                         x_valid=x_valid, x_valid_x=x_valid_x, window_size=25, debug=False)\n",
    "\n",
    "df = ReverseNormalization.transform()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>EMA6</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA24</th>\n",
       "      <th>labels</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.352501</td>\n",
       "      <td>40.435001</td>\n",
       "      <td>38.305000</td>\n",
       "      <td>38.457500</td>\n",
       "      <td>36.011488</td>\n",
       "      <td>33.162876</td>\n",
       "      <td>29.691369</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>2017-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.790001</td>\n",
       "      <td>39.150002</td>\n",
       "      <td>35.875000</td>\n",
       "      <td>36.139999</td>\n",
       "      <td>36.048206</td>\n",
       "      <td>33.620895</td>\n",
       "      <td>30.207260</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>2017-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.262501</td>\n",
       "      <td>36.875000</td>\n",
       "      <td>34.645000</td>\n",
       "      <td>36.689999</td>\n",
       "      <td>36.231575</td>\n",
       "      <td>34.093064</td>\n",
       "      <td>30.725879</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>2017-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.435001</td>\n",
       "      <td>41.575001</td>\n",
       "      <td>37.169998</td>\n",
       "      <td>41.237499</td>\n",
       "      <td>37.661839</td>\n",
       "      <td>35.192208</td>\n",
       "      <td>31.566809</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>2017-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.582500</td>\n",
       "      <td>42.325001</td>\n",
       "      <td>40.325001</td>\n",
       "      <td>42.025002</td>\n",
       "      <td>38.908457</td>\n",
       "      <td>36.243407</td>\n",
       "      <td>32.403464</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>2017-07-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open       High        Low      Close       EMA6      EMA12  \\\n",
       "In                                                                     \n",
       "0   38.352501  40.435001  38.305000  38.457500  36.011488  33.162876   \n",
       "1   38.790001  39.150002  35.875000  36.139999  36.048206  33.620895   \n",
       "2   36.262501  36.875000  34.645000  36.689999  36.231575  34.093064   \n",
       "3   37.435001  41.575001  37.169998  41.237499  37.661839  35.192208   \n",
       "4   41.582500  42.325001  40.325001  42.025002  38.908457  36.243407   \n",
       "\n",
       "        EMA24 labels prediction    Datetime  \n",
       "In                                           \n",
       "0   29.691369     nn         nn  2017-06-19  \n",
       "1   30.207260     nn         nn  2017-06-26  \n",
       "2   30.725879     nn         nn  2017-07-03  \n",
       "3   31.566809     nn         nn  2017-07-10  \n",
       "4   32.403464     nn         nn  2017-07-17  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from final_evaluation import GetFinalDataframe\n",
    "\n",
    "GetFinalDataframe = GetFinalDataframe()\n",
    "\n",
    "GetFinalDataframe.fit(dates=Dates,\n",
    "                      x_valid=x_valid)\n",
    "\n",
    "df1 = GetFinalDataframe.transform(df)\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry Candle:  Current Open\n",
      "\n",
      "Total Trades:  232\n",
      "Profit Trades:  178\n",
      "Loss Trades:  54\n",
      "\n",
      "Win Ratio: 77.0 %\n",
      "Loss Ratio: 23 %\n",
      "\n",
      "Average profit per trade:  767\n",
      "\n",
      "Gross profit:  177872\n",
      "Gross loss:  -54734\n",
      "\n",
      "Net profit:  123138\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>EMA6</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA24</th>\n",
       "      <th>labels</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>profit</th>\n",
       "      <th>trade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.352501</td>\n",
       "      <td>40.435001</td>\n",
       "      <td>38.305</td>\n",
       "      <td>38.457500</td>\n",
       "      <td>36.011488</td>\n",
       "      <td>33.162876</td>\n",
       "      <td>29.691369</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>-1.637501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.790001</td>\n",
       "      <td>39.150002</td>\n",
       "      <td>35.875</td>\n",
       "      <td>36.139999</td>\n",
       "      <td>36.048206</td>\n",
       "      <td>33.620895</td>\n",
       "      <td>30.207260</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>-1.637501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open       High     Low      Close       EMA6      EMA12      EMA24  \\\n",
       "In                                                                             \n",
       "0   38.352501  40.435001  38.305  38.457500  36.011488  33.162876  29.691369   \n",
       "1   38.790001  39.150002  35.875  36.139999  36.048206  33.620895  30.207260   \n",
       "\n",
       "   labels prediction    Datetime    profit trade  \n",
       "In                                                \n",
       "0      nn         nn  2017-06-19 -1.637501     1  \n",
       "1      nn         nn  2017-06-26 -1.637501     1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from final_evaluation import GetModelPerformance\n",
    "\n",
    "GetModelPerformance = GetModelPerformance()\n",
    "\n",
    "GetModelPerformance.fit(acceptance=0,\n",
    "                        penalization=0,\n",
    "                        entry_candle='Current Open',\n",
    "                        budget=10000,\n",
    "                        export_excel=True)\n",
    "\n",
    "trades_df = GetModelPerformance.transform(df1)\n",
    "trades_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = 1\n",
    "budget = 10000\n",
    "entry_candle = 'Current Open'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trade:  1\n",
      "\n",
      "Budget:  10000\n",
      "\n",
      "Entry price:  50.01\n",
      "Label (target):  50.08\n",
      "Model prediction:  52.73\n",
      "\n",
      "Profit: 1 dollars\n",
      "Real Profit: 199.95 dollars (budget 10000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x414 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mplfinance as mpf\n",
    "\n",
    "def PlotTrade(trade = trade):\n",
    "    Dates = trades_df['Datetime']\n",
    "\n",
    "    print(\"Trade: \", trade)\n",
    "\n",
    "    selected_df = trades_df[trades_df['trade'] == trade]\n",
    "\n",
    "    # Get EMAs\n",
    "    dates = selected_df['Datetime']\n",
    "    ema6 = selected_df['EMA6']\n",
    "    ema6 = ema6[:-1]\n",
    "    ema12 = selected_df['EMA12']\n",
    "    ema12 = ema12[:-1]\n",
    "    ema24 = selected_df['EMA24']\n",
    "    ema24 = ema24[:-1]\n",
    "\n",
    "    datepairs_ema6 = [(d1, d2) for d1, d2 in zip(dates, ema6)]\n",
    "    datepairs_ema12 = [(d1, d2) for d1, d2 in zip(dates, ema12)]\n",
    "    datepairs_ema24 = [(d1, d2) for d1, d2 in zip(dates, ema24)]\n",
    "\n",
    "    # #Format Dataframe\n",
    "    quotes = selected_df.iloc[:, :10]\n",
    "    quotes['Datetime'] = quotes['Datetime'].astype('datetime64')\n",
    "    quotes = quotes.set_index('Datetime')\n",
    "    quotes = quotes.iloc[:, :4]\n",
    "    quotes.columns = ['open', 'high', 'low', 'close']\n",
    "\n",
    "    # Define function to get entry\n",
    "    EntryPriceRow = 0\n",
    "\n",
    "\n",
    "    def GetEntryPriceColl(candle):\n",
    "        if candle == 'Previous High':\n",
    "            EntryPriceColl = 1\n",
    "            EntryPriceRow = 1\n",
    "        if candle == 'Current Open':\n",
    "            EntryPriceColl = 0\n",
    "            EntryPriceRow = 0\n",
    "        if candle == 'Previous Close':\n",
    "            EntryPriceColl = 3\n",
    "            EntryPriceRow = 1\n",
    "        return EntryPriceColl, EntryPriceRow\n",
    "\n",
    "\n",
    "    entry_price_column, entry_price_row = GetEntryPriceColl(entry_candle)  #\n",
    "    # budget = 10000\n",
    "\n",
    "    entry = selected_df.iloc[window_size-1-entry_price_row, entry_price_column]\n",
    "    profit = selected_df.iloc[window_size-1, -1]\n",
    "    real_profit = round((budget / entry)*profit, 2)\n",
    "    print(\"\\nBudget: \", budget)\n",
    "\n",
    "    print(\"\\nEntry price: \", round(entry, 2))\n",
    "    print(\"Label (target): \", round(selected_df.iloc[window_size-1, 7], 2))\n",
    "    print(\"Model prediction: \", round(selected_df.iloc[window_size-1, 8], 2))\n",
    "    print(\"\\nProfit: {} dollars\". format(round(selected_df.iloc[window_size-1, -1], 3)))\n",
    "    print(\"Real Profit: \" + str(real_profit) +\n",
    "        \" dollars (budget \" + str(budget) + \")\")\n",
    "\n",
    "\n",
    "    mpf.plot(quotes, type='candle', alines=dict(alines=[datepairs_ema6, datepairs_ema12, datepairs_ema24], colors=[\n",
    "            'r', 'g', 'b']))  # datepairs_ema12,datepairs_ema24\n",
    "\n",
    "    return selected_df\n",
    "   \n",
    "df = PlotTrade(trade = trade)\n",
    "trade += 1\n",
    "#df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>EMA6</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA24</th>\n",
       "      <th>labels</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>profit</th>\n",
       "      <th>trade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.352501</td>\n",
       "      <td>40.435001</td>\n",
       "      <td>38.305</td>\n",
       "      <td>38.457500</td>\n",
       "      <td>36.011488</td>\n",
       "      <td>33.162876</td>\n",
       "      <td>29.691369</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>-1.637501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.790001</td>\n",
       "      <td>39.150002</td>\n",
       "      <td>35.875</td>\n",
       "      <td>36.139999</td>\n",
       "      <td>36.048206</td>\n",
       "      <td>33.620895</td>\n",
       "      <td>30.207260</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>-1.637501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open       High     Low      Close       EMA6      EMA12      EMA24  \\\n",
       "In                                                                             \n",
       "0   38.352501  40.435001  38.305  38.457500  36.011488  33.162876  29.691369   \n",
       "1   38.790001  39.150002  35.875  36.139999  36.048206  33.620895  30.207260   \n",
       "\n",
       "   labels prediction    Datetime    profit trade  \n",
       "In                                                \n",
       "0      nn         nn  2017-06-19 -1.637501     1  \n",
       "1      nn         nn  2017-06-26 -1.637501     1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'budget' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\01_main.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m GetPerformanceReport \u001b[39m=\u001b[39m GetPerformanceReport()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m GetPerformanceReport\u001b[39m.\u001b[39mfit(entry_candle\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCurrent Open\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                         budget\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                         window_size\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                         export_excel\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m trades_df_final \u001b[39m=\u001b[39m GetPerformanceReport\u001b[39m.\u001b[39;49mtransform(trades_df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z0040jeb/Desktop/MachineLearning/Data%20Science/VSCode/04_StockPrediction/01_main.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m trades_df_final\n",
      "File \u001b[1;32mc:\\Users\\z0040jeb\\Desktop\\MachineLearning\\Data Science\\VSCode\\04_StockPrediction\\final_evaluation.py:354\u001b[0m, in \u001b[0;36mGetPerformanceReport.transform\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[39m# Fill data\u001b[39;00m\n\u001b[0;32m    352\u001b[0m     performance_report\u001b[39m.\u001b[39mloc[row, \u001b[39m'\u001b[39m\u001b[39mEntry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m entry\n\u001b[0;32m    353\u001b[0m     performance_report\u001b[39m.\u001b[39mloc[row, \u001b[39m'\u001b[39m\u001b[39mPerformance\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofit_calculation(\n\u001b[1;32m--> 354\u001b[0m         difference, entry, budget)\n\u001b[0;32m    356\u001b[0m performance_report \u001b[39m=\u001b[39m performance_report\u001b[39m.\u001b[39mfillna(\u001b[39m\"\u001b[39m\u001b[39mnn\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexport_excel \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'budget' is not defined"
     ]
    }
   ],
   "source": [
    "from final_evaluation import GetPerformanceReport\n",
    "\n",
    "GetPerformanceReport = GetPerformanceReport()\n",
    "\n",
    "GetPerformanceReport.fit(entry_candle=\"Current Open\",\n",
    "                        budget=10000,\n",
    "                        window_size=25,\n",
    "                        export_excel=True)\n",
    "\n",
    "trades_df_final = GetPerformanceReport.transform(trades_df)\n",
    "trades_df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('04_stockprediction': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ae9b00e5548af57dc5d4c583df0ad518b3d501960f1be5c69ca4a560e00ae05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
